{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Source\" data-toc-modified-id=\"Data-Source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Source</a></span></li><li><span><a href=\"#Imports-and-Update-The-Latest-Data\" data-toc-modified-id=\"Imports-and-Update-The-Latest-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports and Update The Latest Data</a></span></li><li><span><a href=\"#Historical-air-4-Thai-Data\" data-toc-modified-id=\"Historical-air-4-Thai-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Historical air 4 Thai Data</a></span></li><li><span><a href=\"#Power-Plants\" data-toc-modified-id=\"Power-Plants-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Power Plants</a></span></li><li><span><a href=\"#Weather-Files\" data-toc-modified-id=\"Weather-Files-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Weather Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Assemble-from-raw-data\" data-toc-modified-id=\"Assemble-from-raw-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Assemble from raw data</a></span></li><li><span><a href=\"#Update-weather-all-cities\" data-toc-modified-id=\"Update-weather-all-cities-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Update weather all cities</a></span></li><li><span><a href=\"#Add-New-Weather-Stations-from-URL\" data-toc-modified-id=\"Add-New-Weather-Stations-from-URL-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Add New Weather Stations from URL</a></span></li></ul></li><li><span><a href=\"#Merge-Weather-Data-from-OpenWeatherMap\" data-toc-modified-id=\"Merge-Weather-Data-from-OpenWeatherMap-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Merge Weather Data from OpenWeatherMap</a></span></li><li><span><a href=\"#Holiday-In-Thailand\" data-toc-modified-id=\"Holiday-In-Thailand-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Holiday In Thailand</a></span></li><li><span><a href=\"#Hotspots-Data\" data-toc-modified-id=\"Hotspots-Data-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Hotspots Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fire-For-Chiang-Mai\" data-toc-modified-id=\"Fire-For-Chiang-Mai-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Fire For Chiang Mai</a></span></li><li><span><a href=\"#Impove-Speed-of-Files-reading\" data-toc-modified-id=\"Impove-Speed-of-Files-reading-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Impove Speed of Files reading</a></span></li></ul></li><li><span><a href=\"#Data-From-Hanoi-US-Embassy\" data-toc-modified-id=\"Data-From-Hanoi-US-Embassy-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Data From Hanoi US Embassy</a></span></li><li><span><a href=\"#Vietnam-EPA\" data-toc-modified-id=\"Vietnam-EPA-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Vietnam EPA</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source \n",
    "1. Berekely Earth 'http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/'\n",
    "2. Screaped Air4Thai Data 'http://air4thai.pcd.go.th/webV2/history/'\n",
    "3. CDC Data 'https://www.cmuccdc.org/download_json/'\n",
    "4. Old Air4Thai data from Thailand EPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Update The Latest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pollution data from 3 sources and update weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "\n",
    "#  always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.imports import *\n",
    "from src.data.download_data import *\n",
    "from src.data.read_data import *\n",
    "from src.data.fire_data import *\n",
    "from src.data.vn_data import *\n",
    "from src.data.weather_data import *\n",
    "from src.gen_functions import *\n",
    "from src.features.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_folder='../data/pm25/'\n",
    "a4th_folder='../data/air4thai_hourly/'\n",
    "cm_folder ='../data/cm_proc/'\n",
    "cdc_folder = '../data/cdc_data/'\n",
    "aqm_folder = '../data/aqm_hourly2/'\n",
    "aqm_folder2 = '../data/aqm_hourly3/'\n",
    "w_folder = '../data/weather_cities/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download Berkeley PM2.5 data for all files in http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/\n",
      "100% [............................................................................] 848287 / 848287\n",
      " Download Data for Hanoi, Ha dong and Jakarta\n",
      "100% [............................................................................] 788307 / 788307\n",
      " Download us embassy data for Hanoi and Jakata for 2020\n",
      "100% [............................................................................] 584630 / 584630download more pollution data from Thailand PCD\n",
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a4c736a68a45ad82d11fe5bd877783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Update weather data for all cities\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0056d78ef84b99b927799ed4ca1c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Chiang Mai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 0\n",
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 0\n",
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 0\n",
      "update weather data for  Bangkok\n",
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 0\n",
      "update weather data for  Mueang Chiang Rai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 0\n",
      "update weather data for  Mueang Tak\n",
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 0\n",
      "update weather data for  Yangon\n",
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 0\n",
      "update weather data for  Tada-U\n",
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 0\n",
      "update weather data for  Sikhottabong\n",
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 0\n",
      "update weather data for  Luang Prabang District\n",
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 0\n",
      "update weather data for  Kunming\n",
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 0\n",
      "update weather data for  East Jakarta\n",
      "updateing file: ../data/weather_cities/East_Jakarta.csv\n",
      "missing date 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(cdc_data=False, build_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download Berkeley PM2.5 data for all files in http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/\n",
      "100% [............................................................................] 854648 / 854648\n",
      " Download Data for Hanoi, Ha dong and Jakarta\n",
      "100% [............................................................................] 794279 / 794279\n",
      " Download us embassy data for Hanoi and Jakata for 2020\n",
      "100% [............................................................................] 672072 / 672072download more pollution data from Thailand PCD\n",
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59117118598641f58880f48ae0fa4b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "download data from Chiang Mai University Project (CDC)\n",
      "number of stations 474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e85383d3edd46f693ec4ba2f9c93d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Update weather data for all cities\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edf3de7983c4720b94bb30da13fa790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Chiang Mai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1767565c3b549178aa21115237c72ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4856bb77a6ed4cb19e78026061f98a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 0\n",
      "update weather data for  Bangkok\n",
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674aa66298d84494871a72cbc33f266d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Mueang Chiang Rai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510e00e344a84317a7e45828db098322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Mueang Tak\n",
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56a35c242a45e48d001cdaa93a11e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Yangon\n",
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da0025459dd41db8fff36db447b1f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Tada-U\n",
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9bf3db8335447a9639bab862da2183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Sikhottabong\n",
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fac8bb9d3749d98292ac1698e31867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Luang Prabang District\n",
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74f9a45580e4eb0b3c51dd54598d750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  Kunming\n",
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6d8f6e98be44feb03b785763a73a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "update weather data for  East Jakarta\n",
      "updateing file: ../data/weather_cities/East_Jakarta.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb209e284da4807a22e04941284982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(cdc_data=True, build_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                             | 0/404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stations 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 404/404 [39:15<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "download_cdc_data(station_url='https://www.cmuccdc.org/api/ccdc/stations', \n",
    "                  dl_url= 'https://www.cmuccdc.org/download_json/', \n",
    "                  data_folder='../data/cdc_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [13:48, 18.85s/it]"
     ]
    }
   ],
   "source": [
    "update_last_air4Thai(url='http://air4thai.pcd.go.th/webV2/history/',data_folder='../data/air4thai_hourly/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update weather data \n",
    "\n",
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Soc Son', 'Bangkok', 'Mueang Chiang Rai', 'Mueang Tak','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)\n",
    "\n",
    "for city_json in tqdm(weather_station_info):\n",
    "    \n",
    "    start_date = datetime(2020,1,1)\n",
    "    end_date = datetime.now()\n",
    "    update_weather(city_json, data_folder=w_folder, start_date=start_date, end_date=end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical air 4 Thai Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35t', '36t', 'm9', 'o10', 'o20', 'o22']\n"
     ]
    }
   ],
   "source": [
    "# load stations information for air4 Thai\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "# find stations in Chiangmai and parase that files\n",
    "cm_station_ids = []\n",
    "cm_station_info = []\n",
    "for i, stations in enumerate(station_info):\n",
    "    if 'Chiang Mai' in stations['areaEN']:\n",
    "        cm_station_ids.append(stations['stationID'])\n",
    "        cm_station_info.append(stations)\n",
    "print(cm_station_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save filename ../data/aqm_hourly2/process/35t.csv\n",
      "save filename ../data/aqm_hourly2/process/36t.csv\n"
     ]
    }
   ],
   "source": [
    "# parase historical data \n",
    "for station_id in cm_station_ids:\n",
    "    # find all files that start with this stations\n",
    "    p = Path(aqm_folder)\n",
    "    filenames = []\n",
    "    for i in p.glob('**/*.xlsx'):\n",
    "        if station_id in i.name:\n",
    "            filenames.append(str(i))\n",
    "        \n",
    "    # if filename exist load that file\n",
    "    if len(filenames) >0:\n",
    "\n",
    "        save_filename = aqm_folder + 'process/' + station_id + '.csv'\n",
    "        print('save filename', save_filename)\n",
    "        station_data = read_his_xl(filenames[0])\n",
    "        #print(station_data.head())\n",
    "\n",
    "        # save the data if the dataframe is not empty\n",
    "        if len(station_data)> 0:\n",
    "            station_data.to_csv(save_filename,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cm_proc/35t.csv\n",
      "../data/cm_proc/36t.csv\n",
      "../data/cm_proc/m9.csv\n",
      "../data/cm_proc/o10.csv\n",
      "../data/cm_proc/o20.csv\n",
      "../data/cm_proc/o22.csv\n"
     ]
    }
   ],
   "source": [
    "# combine new and old air4Thai data \n",
    "gas_cols = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5']\n",
    "for station_id in cm_station_ids:\n",
    "    try: \n",
    "        old_data = pd.read_csv(aqm_folder + 'process/'+station_id + '.csv')\n",
    "    except:\n",
    "        old_data = pd.DataFrame()\n",
    "    else:\n",
    "        old_data['datetime'] = pd.to_datetime(old_data['datetime'])\n",
    "        old_data = old_data.set_index('datetime')\n",
    "        # keep only the gass columns\n",
    "        old_data = old_data[gas_cols]\n",
    "    \n",
    "    new_data = pd.read_csv(a4th_folder + station_id + '.csv',na_values='-').set_index('datetime')\n",
    "    new_data.columns = [s.split(' (')[0] for s in new_data.columns]\n",
    "    # keep only the gass columns\n",
    "    new_data = new_data[gas_cols]\n",
    "    # concatinate data and save\n",
    "    data = pd.concat([old_data,new_data])\n",
    "    filename = cm_folder+station_id + '.csv'\n",
    "    print(filename)\n",
    "    data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data1 = pd.read_csv(aqm_folder + 'process/35t.csv')\n",
    "cm_data1['datetime'] = pd.to_datetime(cm_data1['datetime'])\n",
    "cm_data1 = cm_data1.set_index('datetime')\n",
    "# keep only gas columns\n",
    "cm_data1 = cm_data1[['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5']]\n",
    "\n",
    "cm_data2 = pd.read_csv(aqm_folder + 'process/36t.csv')\n",
    "cm_data2['datetime'] = pd.to_datetime(cm_data2['datetime'])\n",
    "cm_data2 = cm_data2.set_index('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour   CO  NO NO2 SO2  NOX      Pressure           Rain  \\\n",
      "0  960101   100  2.6  51  32   5   83                                \n",
      "1  960101   200  2.8  71  30   6  101                                \n",
      "2  960101   300  2.8  75  29   6  104                                \n",
      "3  960101   400  2.5  52  25   5   78                                \n",
      "4  960101   500  1.4  17  21   5   39                                \n",
      "\n",
      "        Rel hum          Temp      Wind dir     Wind speed            CO8  \n",
      "0                                                                          \n",
      "1                                                                    2.45  \n",
      "2                                                                 2.25714  \n",
      "3                                                                  2.1125  \n",
      "4                                                                   1.975  \n",
      "    date  hour        CO  NO            O3 NO2 SO2 NOX PM10 PM2.5 Pressure  \\\n",
      "0  30101   100      1.73  16                38   4  53  NaN   NaN     29.9   \n",
      "1  30101   200      1.79  16                36   3  52  NaN   NaN     29.9   \n",
      "2  30101   300      1.38  12                32   2  44  NaN   NaN     29.9   \n",
      "3  30101   400  0.639999   5                24   2  29  NaN   NaN     29.9   \n",
      "4  30101   500      0.57   4                26   3  30  NaN   NaN     29.9   \n",
      "\n",
      "  Rain  Rel hum  Temp Wind dir Wind speed       CO8  \n",
      "0    0     68.6  27.9      289       1.36      1.07  \n",
      "1    0  68.7999  27.9      341        1.5   1.04625  \n",
      "2    0       69  27.8       13       1.32      1.02  \n",
      "3    0     66.1  27.9       94       1.56  0.982499  \n",
      "4    0     70.5  27.4      115       1.59  0.993749  \n",
      "     date  hour CO SO2 NO NO2 NOX Wind speed Wind dir  Temp  ... Unnamed: 27  \\\n",
      "0  100101   100  -   0  1  13  14       1.37      213  28.4  ...         NaN   \n",
      "1  100101   200  -   0  0  14  15       1.42      218  28.1  ...         NaN   \n",
      "2  100101   300  -   0  2  19  20       1.27      213  27.9  ...         NaN   \n",
      "3  100101   400  -   0  1  18  19       1.12      225  27.8  ...         NaN   \n",
      "4  100101   500  -   1  2  20  22       0.98      247  27.7  ...         NaN   \n",
      "\n",
      "  Unnamed: 28 Unnamed: 29 Unnamed: 30 Unnamed: 31  Unnamed: 32  Unnamed: 33  \\\n",
      "0         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "1         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "2         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "3         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "4         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 34  Unnamed: 35  Unnamed: 36  \n",
      "0          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "     date  hour CO SO2 NO NO2 PM10 O3 PM2.5\n",
      "0  130101   100  -   -  -   -    -  -   NaN\n",
      "1  130101   200  -   -  -   -    -  -   NaN\n",
      "2  130101   300  -   -  -   -    -  -   NaN\n",
      "3  130101   400  -   -  -   -    -  -   NaN\n",
      "4  130101   500  -   -  -   -    -  -   NaN\n",
      "     date  hour CO NO2 Temp O3 PM10 PM2.5\n",
      "0  170301   100  -   -    -  -    -   NaN\n",
      "1  170301   200  -   -    -  -    -   NaN\n",
      "2  170301   300  -   -    -  -    -   NaN\n",
      "3  170301   400  -   -    -  -    -   NaN\n",
      "4  170301   500  -   -    -  -    -   NaN\n",
      "     date  hour CO O3 NO2 SO2\n",
      "0  960101   100  1  6  36   3\n",
      "1  960101   200  1  4  41   2\n",
      "2  960101   300  1  4  39   2\n",
      "3  960101   400  1  4  39   3\n",
      "4  960101   500  1  4  40   5\n",
      "    date  hour   CO  O3 NO2 SO2 PM10\n",
      "0  30101   100  1.1   5  33   5  NaN\n",
      "1  30101   200  1.1   4  36   6  NaN\n",
      "2  30101   300  0.5   6  28   4  NaN\n",
      "3  30101   400  0.3   8  21   3  NaN\n",
      "4  30101   500    0  12  14   3  NaN\n",
      "     date  hour   CO SO2 NO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.5   3  12  11   34   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.4   3   9  13   27   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.4   3  11  12   25   NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.5   3  12  11   24   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.6   4  13  10   31   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "     date  hour   CO SO2 NO2  O3 PM10 PM2.5\n",
      "0  170101   100  0.4   1   2  24   45    44\n",
      "1  170101   200  0.3   1   0  26   58    48\n",
      "2  170101   300  0.3   1   0  26   37    36\n",
      "3  170101   400  0.3   1   0  29   37    35\n",
      "4  170101   500  0.3   0   0  27   39    37\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO  O3 NO2 SO2 PM10\n",
      "0  30101   100       0.7   5  31   2   54\n",
      "1  30101   200       0.7   9  26   2   47\n",
      "2  30101   300       0.5  12  15   2   52\n",
      "3  30101   400  0.599999   6  19   3   40\n",
      "4  30101   500       0.5   3  21   1   64\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO O3 NO2 SO2 PM10\n",
      "0  30101   100  0.799998  2  35   5   51\n",
      "1  30101   200  0.799998  2  33   5   45\n",
      "2  30101   300  0.499998  4  26   1   42\n",
      "3  30101   400  0.599998  3  25   0   37\n",
      "4  30101   500  0.599998  1  27   2   53\n",
      "     date  hour   CO NO2 SO2 O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100    1  28   4  6   65         NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.7  27   3  5   39         NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.2  28   2  6   10         NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.2  29   2  5   16         NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.4  27   3  5   24         NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100    1  18   3  40   26   NaN\n",
      "1  170101   200  0.9  21   4  34   21   NaN\n",
      "2  170101   300  0.9  19   3  35   18   NaN\n",
      "3  170101   400  0.9  17   3  35   16   NaN\n",
      "4  170101   500  0.9  17   3  34   16   NaN\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour   CO O3 NO2 SO2 PM10\n",
      "0  30101   100  1.5  5  47   6   89\n",
      "1  30101   200  1.5  5  44   2   49\n",
      "2  30101   300  1.3  5  36   1   44\n",
      "3  30101   400  1.3  4  33   2   42\n",
      "4  30101   500  1.4  4  32   4   57\n",
      "     date  hour   CO NO2 SO2  O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
      "0  100101   100    1  15   3  16   37         NaN         NaN         NaN   \n",
      "1  100101   200  1.1  19   3  11   31         NaN         NaN         NaN   \n",
      "2  100101   300  1.1  23   3   7   35         NaN         NaN         NaN   \n",
      "3  100101   400  0.7  16   3  13   37         NaN         NaN         NaN   \n",
      "4  100101   500  0.9  15   3  13   30         NaN         NaN         NaN   \n",
      "\n",
      "   ...  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
      "0  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "1  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "2  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "3  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "4  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "     date  hour CO NO2 SO2 O3 PM10 PM2.5\n",
      "0  170101   100  -   -   -  -    -   NaN\n",
      "1  170101   200  -   -   -  -    -   NaN\n",
      "2  170101   300  -   -   -  -    -   NaN\n",
      "3  170101   400  -   -   -  -    -   NaN\n",
      "4  170101   500  -   -   -  -    -   NaN\n",
      "    date  hour    CO(ppm) PM10(มคก./ลบ.ม.)\n",
      "0  10101   100   0.599999               57\n",
      "1  10101   200        1.1               84\n",
      "2  10101   300          1               73\n",
      "3  10101   400  0.0999999               66\n",
      "4  10101   500        0.2               69\n",
      "    date  hour    CO(ppm) PM10(มคก./ลบ.ม.)\n",
      "0  80101   100        0.2               62\n",
      "1  80101   200  0.0999999               64\n",
      "2  80101   300          0               55\n",
      "3  80101   400          0               59\n",
      "4  80101   500          0               54\n",
      "     date  hour CO(ppm) PM10  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
      "0  150101   100     2.2    -         NaN         NaN         NaN         NaN\n",
      "1  150101   200     1.5    -         NaN         NaN         NaN         NaN\n",
      "2  150101   300     1.2    -         NaN         NaN         NaN         NaN\n",
      "3  150101   400     1.1    -         NaN         NaN         NaN         NaN\n",
      "4  150101   500     1.1    -         NaN         NaN         NaN         NaN\n",
      "     date  hour  CO  NO2 PM10 PM2.5\n",
      "0  170601   100 NaN  NaN  NaN   NaN\n",
      "1  170601   200 NaN  NaN  NaN   NaN\n",
      "2  170601   300 NaN  NaN  NaN   NaN\n",
      "3  170601   400 NaN  NaN  NaN   NaN\n",
      "4  170601   500 NaN  NaN  NaN   NaN\n",
      "     date  hour             CO            NO            O3           NO2  \\\n",
      "0  960101   100                                                            \n",
      "1  960101   200                                                            \n",
      "2  960101   300                                                            \n",
      "3  960101   400                                                            \n",
      "4  960101   500                                                            \n",
      "\n",
      "             SO2          PM10  \n",
      "0                               \n",
      "1                               \n",
      "2                               \n",
      "3                               \n",
      "4                               \n",
      "    date  hour             CO            O3           NO2            SO2 PM10\n",
      "0  30101   100            1.7             3            50              7   79\n",
      "1  30101   200            1.6             2            42              5   86\n",
      "2  30101   300                                                             82\n",
      "3  30101   400            1.1             4            32              4   54\n",
      "4  30101   500            1.9             3            37              7   70\n",
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.9  20   0  10   19   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.9  23   0   8   23   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.9  23   0   8   15   NaN         NaN         NaN  ...   \n",
      "3  100101   400    1  25   0   5   20   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.8  15   0  12   16   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 24  Unnamed: 25  Unnamed: 26  Unnamed: 27  Unnamed: 28  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100  0.8  20   2  26   68    58\n",
      "1  170101   200  0.7  19   2  26   47    40\n",
      "2  170101   300  0.7  18   2  24   41    38\n",
      "3  170101   400  0.7  19   1  23   49    41\n",
      "4  170101   500  0.8  20   1  20   47    33\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO O3 NO2 SO2 PM10\n",
      "0  30101   100       1.3  4  36   5   33\n",
      "1  30101   200       1.3  4  34   5   30\n",
      "2  30101   300       0.7  6  24   2   23\n",
      "3  30101   400  0.599999  5  20   2   18\n",
      "4  30101   500         1  3  23   2   23\n",
      "     date  hour   CO NO2 SO2 O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  1.3  32   4  3   35         NaN         NaN         NaN  ...   \n",
      "1  100101   200  1.5  33   7  3   30         NaN         NaN         NaN  ...   \n",
      "2  100101   300  1.3  32   7  3   22         NaN         NaN         NaN  ...   \n",
      "3  100101   400  1.3  30   7  4   15         NaN         NaN         NaN  ...   \n",
      "4  100101   500  1.3  30   5  4   18         NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  Unnamed: 16  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour  CO  NO2 PM10 PM2.5\n",
      "0  170601   100 NaN  NaN  NaN   NaN\n",
      "1  170601   200 NaN  NaN  NaN   NaN\n",
      "2  170601   300 NaN  NaN  NaN   NaN\n",
      "3  170601   400 NaN  NaN  NaN   NaN\n",
      "4  170601   500 NaN  NaN  NaN   NaN\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour   CO O3 NO2 SO2 PM10\n",
      "0  30101   100  3.9  3  47  12   51\n",
      "1  30101   200  4.7  3  46  12   50\n",
      "2  30101   300  2.1  3  34   4   58\n",
      "3  30101   400  2.7  3  33   8   69\n",
      "4  30101   500  3.5  4  37  10   70\n",
      "    date  hour             CO   O3           NO2            SO2           PM10\n",
      "0  40101   100                 NaN                                            \n",
      "1  40101   200                 NaN                                            \n",
      "2  40101   300                 NaN                                            \n",
      "3  40101   400                 NaN                                            \n",
      "4  40101   500                 NaN                                            \n",
      "     date  hour    CO NO2 SO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.36  20   1  12   34   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.25  20   0  11   60   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.22  21   0   9   48   NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.28  20   1   9   14   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.24  17   0  12   26   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "     date  hour   CO NO2  O3 PM10 PM2.5\n",
      "0  170101   100    -   -   -   58    33\n",
      "1  170101   200  0.9  18  23   46    32\n",
      "2  170101   300  0.9  18  22   41    28\n",
      "3  170101   400  0.9  18  21   38    25\n",
      "4  170101   500  0.9  17  20   37    24\n",
      "    date  hour             CO            O3           NO2            SO2  \\\n",
      "0  50101   100                                                             \n",
      "1  50101   200                                                             \n",
      "2  50101   300                                                             \n",
      "3  50101   400                                                             \n",
      "4  50101   500                                                             \n",
      "\n",
      "            PM10  \n",
      "0                 \n",
      "1                 \n",
      "2                 \n",
      "3                 \n",
      "4                 \n",
      "     date  hour   CO NO2 SO2 O3 PM10 PM2.5 Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.9  15   4  3   37   NaN        NaN         NaN  ...   \n",
      "1  100101   200  0.9  14   4  3   37   NaN        NaN         NaN  ...   \n",
      "2  100101   300  0.9  14   4  3   46   NaN        NaN         NaN  ...   \n",
      "3  100101   400  0.9  14   5  4   50   NaN        NaN         NaN  ...   \n",
      "4  100101   500  0.8  14   4  3   52   NaN        NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "     date  hour NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100   7   2  31   66    52\n",
      "1  170101   200  11   2  26   44    36\n",
      "2  170101   300   9   2  27   38    37\n",
      "3  170101   400   2   1  32   38    36\n",
      "4  170101   500   1   1  33   37    34\n",
      "['02t', '03t', '05t', '11t', '12t', '50t', '52t', '53t', '59t', '61t']\n",
      "['10t', '54t']\n"
     ]
    }
   ],
   "source": [
    "# process bangkok data\n",
    "station_ids = ['02t',\n",
    " '03t',\n",
    " '05t',\n",
    " '10t',\n",
    " '11t',\n",
    " '12t',\n",
    " '50t',\n",
    " '52t',\n",
    " '53t',\n",
    " '54t',\n",
    " '59t',\n",
    " '61t']\n",
    "\n",
    "good_stations = []\n",
    "bad_stations = []\n",
    "for ids in station_ids:\n",
    "    path = Path(aqm_folder)\n",
    "    files = [*path.rglob(f'({ids})*.xlsx')]\n",
    "    try:\n",
    "        df = read_his_xl(files[0])\n",
    "    except:\n",
    "        bad_stations.append(ids)\n",
    "    else:\n",
    "        good_stations.append(ids)\n",
    "        df.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/aqm_hourly2/process/'+ids+'.csv')\n",
    "        \n",
    "print(good_stations)\n",
    "print(bad_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://th.wikipedia.org/wiki/%E0%B8%A3%E0%B8%B2%E0%B8%A2%E0%B8%8A%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B9%82%E0%B8%A3%E0%B8%87%E0%B9%84%E0%B8%9F%E0%B8%9F%E0%B9%89%E0%B8%B2%E0%B9%83%E0%B8%99%E0%B9%84%E0%B8%97%E0%B8%A2'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_power_stations_in_Thailand'\n",
    "table_list = pd.read_html(url)\n",
    "len(table_list)\n",
    "p_folder = '../data/power_plants/'\n",
    "for i, table in enumerate(table_list):\n",
    "    table.to_csv(p_folder + f'table_eng{i}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/*/')\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkk 13\n",
      "chiang-mai 36\n",
      "chiang-rai 25\n",
      "kungming 24\n",
      "luang-prabang 24\n",
      "sikhottabong 39\n",
      "tada_u 24\n",
      "tak 26\n",
      "yangong 29\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    city_name = Path(folder).name\n",
    "    parent_folder = Path(folder).parent\n",
    "    w_files = glob(folder + '/*.csv')\n",
    "    print(city_name, len(w_files))\n",
    "    filename = str(Path(folders[0]).parent) + '/' + city_name + '.csv'\n",
    "    \n",
    "    # concatenate all files \n",
    "    df_all = pd.DataFrame()\n",
    "    for file in w_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    \n",
    "    # drop missing value \n",
    "    df_all['datetime'] = pd.to_datetime(df_all['date'])\n",
    "    df_all.drop('date',axis=1, inplace=True)\n",
    "    df_all = df_all.sort_values('datetime')\n",
    "    df_all = df_all.drop_duplicates('datetime', ignore_index=True)\n",
    "    \n",
    "    # save file\n",
    "    df_all.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing date for chiang-mai data \n",
    "df_all = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv')\n",
    "df_all['datetime'] = pd.to_datetime(df_all['datetime'] )\n",
    "# find exisiting date \n",
    "ex_date = df_all['datetime'].dt.strftime('%Y-%m-%d').unique()\n",
    "ex_date = set(ex_date)\n",
    "# calculate the datelist \n",
    "start_date = datetime(2000, 10, 1)\n",
    "stop_date = datetime.now()\n",
    "date_range = pd.date_range(start_date, stop_date).strftime('%Y-%m-%d')\n",
    "missing_date = list(set(date_range).difference(ex_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'Mueang Chiang Mai', 'province': 'Chiang Mai', 'country': 'Thailand', 'station_name': 'Chiang Mai International Airport Station', 'specific_url': 'th/mueang-chiang-mai/', 'latitude': '18.8 °N', 'longitude': '98.97 °E'}\n"
     ]
    }
   ],
   "source": [
    "with open('../data/weather_cities/weather_station_info.json','r') as f:\n",
    "    station_dict_list = json.load(f)\n",
    "   \n",
    "i = 0 \n",
    "city_json = station_dict_list[i]\n",
    "print(city_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/mueang-chiang-mai_weather.csv 2000-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\src\\data\\dl_weather.py:20: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 20 of the file ..\\src\\data\\dl_weather.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(innerhtml)\n"
     ]
    }
   ],
   "source": [
    " bad_date_df = scrape_weather(city_json, date_range=missing_date, data_folder='C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333126, 11)\n"
     ]
    }
   ],
   "source": [
    "# weather data \n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv'\n",
    "wea = pd.read_csv(filename)\n",
    "wea['datetime']  = pd.to_datetime(wea['datetime'])\n",
    "# roud datetiem to whole 30 mins \n",
    "wea['datetime'] = wea['datetime'].dt.round('30T')\n",
    "\n",
    "dates = wea['datetime'].dropna().dt.date.unique()\n",
    "\n",
    "# fill in the missing value\n",
    "new_datetime = pd.date_range(start=dates[0], end=dates[-1], freq='30T') \n",
    "new_weather = pd.DataFrame(new_datetime, columns=['datetime'])\n",
    "new_weather = new_weather.merge(wea, on='datetime',how='left')\n",
    "print(new_weather.shape)\n",
    "\n",
    "# remove strange T reading\n",
    "lowest_t = 5 \n",
    "idx = new_weather[new_weather['Temperature(C)']< lowest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "highest_t = 60\n",
    "idx = new_weather[new_weather['Temperature(C)']> highest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "new_weather = new_weather.fillna(method='ffill',limit=12)\n",
    "new_weather = new_weather.fillna(method='bfill',limit=12)\n",
    "new_weather = new_weather.set_index('datetime')\n",
    "new_weather = new_weather.dropna(how='all').reset_index()\n",
    "new_weather.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Assemble from raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# weather folder\n",
    "w_folder = '../data/weather_cities/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Mueang Chiang Rai', 'Mueang Tak','Bangkok','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "36\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "25\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Mueang_Tak.csv\n",
      "26\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Bangkok.csv\n",
      "13\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime', 'Temperature(F)', 'Dew Point(F)',\n",
      "       'Precip Accum(in)'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Yangon.csv\n",
      "28\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Tada-U.csv\n",
      "23\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Sikhottabong.csv\n",
      "39\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Luang_Prabang_District.csv\n",
      "24\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Kunming.csv\n",
      "24\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# concatenate raw data files\n",
    "for city_json in weather_station_info: \n",
    "    # read existing file \n",
    "    city_name = ('_').join(city_json['city_name'].split(' '))\n",
    "    current_filename = w_folder + city_name + '.csv'\n",
    "    print(current_filename)\n",
    "    \n",
    "    # locate file in the city folder\n",
    "    files = glob(w_folder + city_name + '/*.csv')\n",
    "    print(len(files))\n",
    "    \n",
    "    weather_all = pd.DataFrame()\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if 'date'== df.columns[-1]:\n",
    "                df.columns = df.columns.str.replace('date','datetime')\n",
    "            weather_all = pd.concat([weather_all, df],ignore_index=True)\n",
    "        \n",
    "    print(weather_all.columns)\n",
    "    weather_all.to_csv(current_filename, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities\\Bangkok.csv\n",
      "../data/weather_cities\\Kunming.csv\n",
      "../data/weather_cities\\Luang_Prabang_District.csv\n",
      "../data/weather_cities\\Mueang_Chiang_Mai.csv\n",
      "../data/weather_cities\\Mueang_Chiang_Rai.csv\n",
      "../data/weather_cities\\Mueang_Tak.csv\n",
      "../data/weather_cities\\Sikhottabong.csv\n",
      "../data/weather_cities\\Tada-U.csv\n",
      "../data/weather_cities\\Yangon.csv\n"
     ]
    }
   ],
   "source": [
    "# fix the unit of windspeed \n",
    "files = glob(w_folder + '/*.csv')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df[['Wind Speed(mph)', 'Wind Gust(mph)']] = df[['Wind Speed(mph)', 'Wind Gust(mph)']]*1.60934\n",
    "    df[['Wind Speed(mph)', 'Wind Gust(mph)']] = df[['Wind Speed(mph)', 'Wind Gust(mph)']].round(0)\n",
    "    df.columns = df.columns.str.replace('mph', 'kmph')\n",
    "    df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate datetime \n",
    "files = glob(w_folder + '/*.csv')\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df = df.drop_duplicates('datetime')\n",
    "    df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill the missing value in raw Weather Data \n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = fill_missing_weather(df,limit=12)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update weather all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities/Mueang_Chiang_Mai.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime.now()\n",
    "city_json = weather_station_info[i]\n",
    "# read existing file \n",
    "city_name = ('_').join(city_json['city_name'].split(' '))\n",
    "current_filename = w_folder + city_name + '.csv'\n",
    "print(current_filename)\n",
    "\n",
    "# obtain a list of existed dates\n",
    "wea = pd.read_csv(current_file)\n",
    "wea['datetime'] = pd.to_datetime(wea['datetime'])\n",
    "# find exisiting date \n",
    "ex_date = wea['datetime'].dt.strftime('%Y-%m-%d').unique()\n",
    "ex_date = set(ex_date)\n",
    "\n",
    "# calculate the missing dates \n",
    "date_range = pd.date_range(start_date, end_date).strftime('%Y-%m-%d')\n",
    "missing_date = list(set(date_range).difference(ex_date))\n",
    "missing_date.sort()\n",
    "len(missing_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Mueang Chiang Rai', 'Mueang Tak','Bangkok','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                               | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:28, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:02, 30.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:35, 30.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:04, 30.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:33, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:02, 29.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:30, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:00, 29.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:29, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [04:59, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:32, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:05, 31.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:35, 30.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:04, 30.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:34, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:03, 29.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:37, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:07, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:39, 31.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:11, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:40, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:08, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:42, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:14, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:42, 30.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:10, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:42, 30.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:10, 29.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:42, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:11, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:40, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:09, 29.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:40, 29.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:09, 29.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:39, 29.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:09, 29.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:41, 30.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:14, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:47, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:16, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:45, 30.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:19, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:50, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:20, 30.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:49, 30.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:18, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:51, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:19, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:48, 29.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:18, 29.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:47, 29.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:17, 29.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:52, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:21, 30.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:49, 29.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:20, 30.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:49, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:20, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:51, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:20, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [30:51, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:19, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:50, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:23, 30.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:51, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:21, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:54, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:22, 30.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [34:50, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:19, 29.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [35:47, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:18, 29.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [36:47, 29.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:19, 30.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [37:50, 30.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:18, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [38:46, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:15, 29.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [39:43, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:11, 28.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [40:40, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:10, 28.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [41:38, 28.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:06, 28.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [42:35, 28.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:05, 29.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [43:34, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:03, 28.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [44:31, 28.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:03, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [45:34, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:12, 32.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [46:44, 32.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:16, 32.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [47:50, 32.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [48:38, 37.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:11, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [49:48, 36.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:20, 35.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [50:53, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [51:24, 33.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [51:57, 33.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [52:35, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [53:10, 34.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [53:43, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [54:15, 33.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [54:47, 33.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [55:20, 32.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [55:51, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [56:19, 31.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [56:53, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [57:22, 31.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [57:54, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [58:25, 31.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [58:57, 31.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [59:27, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [59:58, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:00:28, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:00:57, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:01:27, 30.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:01:56, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:02:25, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:02:55, 29.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:03:25, 29.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:03:56, 30.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:04:26, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:04:55, 29.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:05:24, 30.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|██████████▊                                                                                      | 1/9 [1:05:46<8:46:09, 3946.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:34, 34.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:07, 33.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:36, 32.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:04, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:37, 31.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:10, 32.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:39, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:07, 30.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:37, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:05, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:38, 30.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:06, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:34, 29.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:02, 28.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:31, 28.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:00, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:29, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [08:58, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:26, 28.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [09:54, 28.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:22, 28.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [10:53, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:22, 29.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [11:51, 29.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:20, 29.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [12:50, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:24, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [13:52, 29.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:20, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [14:49, 29.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:19, 29.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [15:50, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:23, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [16:52, 30.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:21, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [17:49, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:18, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [18:49, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:17, 29.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [19:48, 29.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:21, 30.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [20:52, 30.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:21, 30.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [21:50, 29.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:19, 29.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [22:49, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:18, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [23:47, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:18, 29.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [24:47, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:16, 29.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [25:46, 29.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:15, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [26:44, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:13, 29.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [27:42, 29.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:10, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [28:40, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:09, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [29:38, 29.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [30:08, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [30:37, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:06, 29.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [31:35, 29.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:04, 29.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [32:32, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:01, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [33:29, 28.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [33:58, 28.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [34:27, 28.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [34:56, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [35:24, 28.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [35:54, 28.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [36:23, 29.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [36:52, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [37:20, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [37:49, 28.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [38:18, 28.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [38:46, 28.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [39:15, 28.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [39:44, 28.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [40:12, 28.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [40:42, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [41:11, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [41:39, 28.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [42:08, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [42:40, 29.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [43:09, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [43:38, 29.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [44:06, 29.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [44:35, 28.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [45:03, 28.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [45:32, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [46:01, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [46:30, 28.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [46:59, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [47:27, 28.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [47:57, 28.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [48:27, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [48:57, 29.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [49:26, 29.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [49:56, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [50:24, 29.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [50:54, 29.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [51:23, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [51:51, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [52:20, 28.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [52:49, 28.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [53:33, 33.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [54:02, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [54:31, 31.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [55:00, 30.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [55:30, 30.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [55:59, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [56:29, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [56:58, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [57:27, 29.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [57:56, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [58:25, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [58:55, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [59:24, 29.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [59:53, 29.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:00:23, 29.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|█████████████████████▌                                                                           | 2/9 [2:06:30<7:29:50, 3855.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:40, 40.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:13, 38.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:44, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:16, 35.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:47, 33.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:17, 32.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:53, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:23, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:01, 34.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:36, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:07, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:37, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:09, 32.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:40, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:11, 31.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:42, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:13, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:43, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:15, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:46, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [11:27, 33.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:59, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:31, 33.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:05, 33.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:37, 32.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:10, 32.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:40, 32.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:15, 32.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:45, 32.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [16:20, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:52, 32.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [17:23, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:54, 31.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [18:26, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [18:59, 32.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [19:31, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [20:05, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [20:37, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [21:10, 32.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [21:43, 32.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [22:17, 33.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [22:50, 32.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:21, 32.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:55, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [24:26, 32.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [25:02, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [25:33, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [26:03, 31.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [26:37, 32.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [27:07, 31.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [27:39, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [28:13, 32.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [28:45, 32.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:17, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [29:49, 32.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:21, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [30:52, 31.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [31:23, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [31:54, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [32:24, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [32:54, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [33:27, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [33:59, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [34:32, 31.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [35:08, 33.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [35:42, 33.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [36:15, 33.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [36:48, 33.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [37:19, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [37:50, 32.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [38:20, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [38:51, 31.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [39:22, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [39:53, 31.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [40:24, 31.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [40:57, 31.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [41:28, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [42:01, 31.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [42:31, 31.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [43:07, 32.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [43:38, 32.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [44:10, 32.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [44:42, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [45:16, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [45:47, 32.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [46:20, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [46:50, 31.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [47:22, 31.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [47:52, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [48:23, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [48:54, 31.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [49:26, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [49:59, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [50:31, 32.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [51:06, 32.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [51:37, 32.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [52:09, 32.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [52:40, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [53:10, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [53:42, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [54:13, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [54:44, 31.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [55:17, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [55:48, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [56:19, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [56:49, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [57:20, 31.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [57:53, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [58:25, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [58:57, 31.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [59:27, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:00:05, 33.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:00:36, 32.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:01:07, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:01:39, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:02:13, 32.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:08:41, 139.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:09:20, 109.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:09:51, 85.79s/it] \u001b[A\u001b[A\n",
      "\n",
      "120it [1:10:23, 69.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:10:59, 59.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:11:33, 51.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:12:08, 35.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████████████████████████▎                                                                | 3/9 [3:18:58<6:40:19, 4003.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:33, 33.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:05, 33.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:34, 31.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:06, 31.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:39, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:07, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:35, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:03, 29.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:32, 29.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:05, 30.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:38, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:10, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:38, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:12, 31.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:47, 32.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:15, 31.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:43, 30.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:15, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:48, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:17, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:48, 30.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:20, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:52, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:24, 31.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:51, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:23, 30.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:55, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:27, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:55, 30.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:27, 30.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:55, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:27, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:54, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:22, 29.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:54, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:26, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:58, 31.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:31, 31.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [20:02, 31.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:35, 31.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [21:02, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:36, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [22:08, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:36, 30.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [23:04, 29.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:31, 29.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [24:03, 29.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:32, 29.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [25:05, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:37, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [26:04, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:36, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [27:09, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:42, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [28:10, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:38, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [29:07, 29.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:37, 29.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [30:09, 30.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:41, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [31:09, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:41, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [32:10, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:38, 29.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [33:06, 29.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:34, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [34:06, 29.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:39, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [35:07, 29.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:39, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [36:12, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:45, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [37:16, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:44, 30.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [38:12, 29.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:45, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [39:13, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:46, 30.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [40:14, 30.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:42, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [41:10, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:42, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [42:10, 29.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:38, 28.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [43:10, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:44, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [44:16, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:48, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [45:15, 30.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:44, 29.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [46:16, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:48, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [47:21, 31.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:52, 31.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [48:39, 36.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [49:08, 33.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:39, 33.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [50:11, 32.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:39, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [51:07, 30.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [51:35, 29.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [52:08, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [52:41, 31.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [53:08, 30.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [53:42, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [54:15, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [54:43, 30.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [55:17, 31.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [55:49, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [56:17, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [56:45, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [57:13, 29.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [57:42, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [58:11, 29.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [58:47, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [59:21, 32.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:00:14, 38.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:01:46, 54.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:02:22, 48.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:02:52, 43.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:03:21, 38.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:03:56, 37.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:04:30, 36.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:04:59, 34.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:05:27, 32.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:05:55, 31.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:06:25, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:07:07, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|███████████████████████████████████████████                                                      | 4/9 [4:26:36<5:34:58, 4019.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:35, 35.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:13, 36.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:48, 36.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:23, 35.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:58, 35.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:33, 35.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:10, 35.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:42, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:16, 34.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:49, 34.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:21, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:52, 32.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:26, 33.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:04, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:38, 34.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:12, 34.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:49, 35.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:23, 34.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:57, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [11:27, 33.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [12:01, 33.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [12:36, 33.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [13:05, 32.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:42, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [14:17, 34.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:52, 34.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [15:23, 33.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:57, 33.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [16:29, 33.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [17:04, 33.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [17:41, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [18:16, 34.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [18:50, 34.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [20:25, 52.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [20:59, 47.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [21:33, 43.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [22:05, 39.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [22:40, 38.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [23:14, 36.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [23:50, 36.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [24:26, 36.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [25:03, 36.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [26:38, 54.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [27:13, 48.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [27:47, 44.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [28:22, 41.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [28:57, 39.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [29:30, 37.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [30:09, 37.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [30:45, 37.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [32:20, 54.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [32:54, 48.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [33:32, 45.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [34:10, 43.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [34:45, 40.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [36:19, 56.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [36:54, 50.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [37:28, 45.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [38:02, 42.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [38:38, 40.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [39:12, 38.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [39:42, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [40:17, 35.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [40:48, 34.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [41:22, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [41:52, 32.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [42:25, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [43:00, 33.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [43:31, 32.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [44:05, 33.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [44:39, 33.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [45:15, 34.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [45:49, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [46:23, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [46:55, 33.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [47:26, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [48:02, 33.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [48:41, 35.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [49:15, 34.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [49:45, 33.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [50:19, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [50:56, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [51:32, 34.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [52:07, 35.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [52:44, 35.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [53:15, 34.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [54:03, 38.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [54:39, 37.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [55:17, 37.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [55:51, 36.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [56:26, 36.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [56:59, 35.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [57:33, 34.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [58:06, 34.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [58:40, 34.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [59:13, 33.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [59:43, 32.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [1:00:15, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [1:00:51, 33.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [1:01:25, 33.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [1:01:55, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [1:02:28, 32.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [1:03:01, 32.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [1:03:34, 32.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [1:04:05, 32.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [1:04:39, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:05:09, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:05:40, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:06:11, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:06:44, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:07:15, 31.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:07:46, 31.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:08:20, 32.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:08:51, 32.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:09:23, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:10:03, 34.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:10:33, 33.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:11:07, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:11:38, 32.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:12:09, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:12:41, 31.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:13:17, 33.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:13:47, 35.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████████████████████████████████████▉                                           | 5/9 [5:40:52<4:36:42, 4150.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:41, 41.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:11, 38.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:41, 35.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:13, 34.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:43, 33.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:11, 31.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:41, 31.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:10, 30.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:39, 30.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:08, 29.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:46, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:15, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:46, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:15, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:45, 30.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:14, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:44, 29.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:17, 30.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:50, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:19, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:54, 32.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:29, 32.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:03, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:37, 33.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:10, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:39, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:11, 32.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:41, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:10, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:43, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:12, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:45, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:18, 31.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:47, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [18:17, 30.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:45, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [19:18, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:48, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [20:18, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:52, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [21:21, 30.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:53, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:25, 49.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:55, 43.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [25:25, 57.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [25:55, 49.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [26:23, 42.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [26:57, 40.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [27:27, 37.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [27:56, 34.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [28:25, 32.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [28:57, 32.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [29:26, 31.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:54, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [30:23, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:53, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [31:29, 31.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [32:01, 31.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [32:30, 31.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [34:01, 48.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [35:32, 61.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [36:07, 53.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [36:36, 46.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [37:09, 42.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [37:42, 39.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [38:12, 36.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [38:46, 35.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [39:14, 33.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [39:44, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [40:16, 32.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [40:55, 34.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [41:23, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [41:56, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [42:25, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [42:54, 30.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [43:27, 31.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [43:57, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [44:26, 30.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [44:55, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [45:25, 29.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [45:58, 30.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [46:31, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [46:59, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [47:32, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [48:04, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [48:37, 31.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [49:06, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [49:39, 31.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [50:12, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [50:49, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [51:19, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [51:53, 32.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [52:21, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [52:55, 32.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [53:23, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [53:53, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [54:26, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [54:55, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [56:19, 46.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [56:48, 41.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [57:22, 39.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [57:51, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [58:20, 34.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [58:52, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [59:21, 32.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [59:54, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:00:25, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:00:54, 31.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:01:27, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:01:58, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:02:27, 30.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:02:56, 30.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:03:28, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:03:58, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:04:30, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:05:04, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:05:37, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:06:05, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:06:34, 30.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:07:04, 30.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:07:38, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:08:10, 31.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:08:39, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|████████████████████████████████████████████████████████████████▋                                | 6/9 [6:50:02<3:27:31, 4150.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:55, 55.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:33, 50.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [02:05, 44.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:44, 43.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [03:22, 41.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:55, 38.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:26, 36.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:56, 34.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:26, 33.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:56, 32.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:32, 33.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [07:03, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:36, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:09, 32.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:40, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:10, 31.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:39, 30.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:10, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:39, 30.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [11:09, 30.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [11:40, 30.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [12:12, 30.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:42, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:12, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:45, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:15, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:44, 30.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:17, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:50, 31.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [16:19, 30.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:52, 31.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [17:26, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:59, 32.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [18:32, 32.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [19:02, 31.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [19:32, 31.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [20:01, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [20:37, 32.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [21:11, 32.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [21:41, 31.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [22:11, 31.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [22:40, 30.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:14, 31.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:43, 30.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [24:17, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [24:46, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [25:15, 30.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [25:49, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [26:19, 30.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [26:48, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [27:22, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [27:57, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [28:36, 34.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:09, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [29:43, 33.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:15, 33.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [30:48, 33.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [31:22, 33.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [31:53, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [32:26, 32.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [32:57, 32.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [33:27, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [34:00, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [34:30, 31.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [35:01, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [35:33, 31.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [36:03, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [36:44, 33.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [37:14, 32.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [37:44, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [39:20, 51.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [39:49, 44.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [40:22, 41.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [40:52, 37.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [41:21, 35.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [41:54, 34.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [42:24, 33.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [42:55, 32.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [43:33, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [44:06, 33.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [44:41, 34.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [45:14, 33.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [45:47, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [46:17, 32.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [46:46, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [47:19, 31.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [47:48, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [48:18, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [48:47, 30.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [49:16, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [49:50, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [50:19, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [50:49, 30.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [51:19, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [51:52, 31.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [52:25, 31.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [52:58, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [53:28, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [53:59, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [54:28, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [54:58, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [55:33, 31.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [56:06, 32.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [56:42, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [57:12, 32.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [57:44, 32.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [58:14, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [58:44, 30.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [59:14, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [59:48, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:00:22, 32.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:00:55, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:01:30, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:02:07, 34.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:03:40, 52.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:04:15, 47.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:04:49, 43.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:05:20, 39.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:05:56, 38.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:06:32, 37.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:07:07, 36.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:07:37, 34.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:08:16, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████████████████▍                     | 7/9 [7:58:49<2:18:06, 4143.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:49, 49.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:29, 46.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [02:00, 41.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:37, 40.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [03:09, 37.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:46, 37.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:22, 37.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:59, 36.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:35, 36.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [06:10, 36.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:45, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [07:17, 34.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:51, 34.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:25, 34.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [09:01, 34.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:36, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [10:07, 33.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:45, 34.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [11:24, 36.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [12:02, 36.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [12:42, 37.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [13:17, 37.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [13:51, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [15:24, 53.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [16:01, 48.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [16:35, 43.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [17:08, 40.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [17:55, 42.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [18:29, 39.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [19:04, 38.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [19:41, 38.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [20:18, 37.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [20:52, 36.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [21:28, 36.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [22:02, 35.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [22:37, 35.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [23:13, 35.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [23:51, 36.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [24:25, 35.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [24:56, 34.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [25:31, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [26:02, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [26:32, 32.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [27:08, 33.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [27:47, 35.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [28:23, 35.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [28:58, 35.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [29:31, 34.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [30:06, 34.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [30:37, 33.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [31:12, 34.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [31:47, 34.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [32:22, 34.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [33:00, 35.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [33:35, 35.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [34:05, 33.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [34:41, 34.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [35:16, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [35:47, 33.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [36:22, 33.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [36:54, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [37:24, 32.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [38:00, 33.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [38:35, 34.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [39:09, 34.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [39:44, 34.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [40:20, 34.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [41:06, 38.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [41:43, 37.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [42:19, 37.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [43:55, 54.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [44:29, 48.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [45:04, 44.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [45:40, 42.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [46:16, 40.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [46:51, 38.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [47:26, 37.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [47:57, 35.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [48:34, 35.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [49:09, 35.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [49:45, 35.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [50:20, 35.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [50:53, 34.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [51:27, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [52:02, 34.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [52:35, 34.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [53:08, 33.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [53:45, 34.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [54:18, 34.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [54:52, 34.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [55:26, 34.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [56:00, 34.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [56:33, 33.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [57:04, 32.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [57:42, 34.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [58:16, 34.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [58:48, 33.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [59:23, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [59:56, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [1:00:32, 34.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [1:01:08, 34.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [1:01:42, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [1:02:17, 34.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [1:02:54, 35.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [1:03:25, 33.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [1:04:00, 34.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:04:30, 33.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:05:01, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:05:37, 33.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:06:11, 33.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:06:49, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:07:20, 33.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:07:59, 35.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:08:33, 34.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:09:07, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:09:41, 34.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:10:16, 34.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:10:47, 33.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:11:23, 34.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:11:54, 33.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:12:29, 33.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:13:03, 33.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:13:38, 34.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:14:12, 34.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:14:46, 34.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:15:22, 34.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:15:56, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:16:31, 34.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "129it [1:17:06, 35.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████▏          | 8/9 [9:16:27<1:11:37, 4297.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:30, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:03, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:30, 30.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:05, 31.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:37, 31.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:05, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:34, 30.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:06, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:38, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:10, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:42, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:17, 32.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:46, 31.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:17, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:49, 31.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:21, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:52, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:25, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:57, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:26, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:57, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:25, 30.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:57, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:25, 29.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:53, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:22, 29.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:49, 28.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:17, 28.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:48, 29.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:17, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:44, 28.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:12, 28.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:41, 28.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:08, 28.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:40, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:11, 29.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:43, 30.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:15, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:43, 30.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:15, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:43, 29.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:14, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:46, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:17, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:50, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:18, 30.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:48, 30.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:19, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:47, 29.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:19, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:47, 29.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:20, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:52, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:23, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:55, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:26, 31.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:57, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:29, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:57, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:29, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [31:00, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:28, 30.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:56, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:24, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:53, 29.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:22, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:54, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:26, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [34:54, 29.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:26, 30.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [35:58, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:31, 31.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [37:03, 31.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:33, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [38:04, 31.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:33, 30.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [39:01, 29.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:33, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [40:02, 29.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:35, 30.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [41:09, 31.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:41, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [42:08, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:40, 30.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [43:09, 30.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:37, 29.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [44:05, 29.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:32, 28.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [45:01, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:29, 28.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [46:01, 29.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:28, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [47:00, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:31, 30.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [48:03, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [48:31, 29.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:02, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [49:34, 30.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:02, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [50:30, 29.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [50:57, 28.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [51:25, 28.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [51:57, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [52:24, 28.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [52:53, 28.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [53:24, 29.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [53:51, 28.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [54:22, 29.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [54:50, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [55:18, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [55:46, 28.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [56:17, 29.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [56:49, 29.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [57:18, 29.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [57:49, 30.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [58:21, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [58:50, 30.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [59:25, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [59:53, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:00:26, 31.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:01:00, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:01:28, 30.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:02:01, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:02:30, 30.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:02:59, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:03:27, 29.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:03:58, 30.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:04:31, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "129it [1:05:04, 30.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [10:21:56<00:00, 4146.29s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for city_json in tqdm(weather_station_info):\n",
    "    \n",
    "    start_date = datetime(2020,1,1)\n",
    "    end_date = datetime.now()\n",
    "    update_weather(city_json, data_folder=w_folder, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add New Weather Stations from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'city_name': 'Mueang Chiang Mai',\n",
       "  'province': 'Chiang Mai',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Chiang Mai International Airport Station',\n",
       "  'specific_url': 'th/mueang-chiang-mai/',\n",
       "  'latitude': '18.8 °N',\n",
       "  'longitude': '98.97 °E'},\n",
       " {'city_name': 'Mueang Chiang Rai',\n",
       "  'province': 'Chiang Rai',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Chiang Rai Station',\n",
       "  'specific_url': 'th/mueang-chiang-rai/',\n",
       "  'latitude': '19.91 °N',\n",
       "  'longitude': '99.83 °E'},\n",
       " {'city_name': 'Mueang Tak',\n",
       "  'province': 'Tak',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Tak Airport Station',\n",
       "  'specific_url': 'th/mueang-tak/',\n",
       "  'latitude': '16.87 °N',\n",
       "  'longitude': '99.13 °E'},\n",
       " {'city_name': 'Mueang Mae Hong Son',\n",
       "  'province': 'Mae Hong Son',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Mae Hong Son Airport Station',\n",
       "  'specific_url': 'th/mueang-mae-hong-son/',\n",
       "  'latitude': '19.3 °N',\n",
       "  'longitude': '97.97 °E'},\n",
       " {'city_name': 'Mueang Nan',\n",
       "  'province': 'Nan',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Nan Airport Station',\n",
       "  'specific_url': 'th/mueang-nan/',\n",
       "  'latitude': '18.78 °N',\n",
       "  'longitude': '100.77 °E'},\n",
       " {'city_name': 'Sawankhalok',\n",
       "  'province': 'Sukhothai',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Sukhothai Airport Station',\n",
       "  'specific_url': 'th/sawankhalok/',\n",
       "  'latitude': '17.31 °N',\n",
       "  'longitude': '99.83 °E'},\n",
       " {'city_name': 'Bangkok',\n",
       "  'province': 'Bangkok Metropolitan Region',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Don Mueang International Airport Station',\n",
       "  'specific_url': 'th/bangkok/',\n",
       "  'latitude': '13.91 °N',\n",
       "  'longitude': '100.59 °E'},\n",
       " {'city_name': 'Bang Phli',\n",
       "  'province': 'Samut Prakan',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'Suvarnabhumi Airport Station',\n",
       "  'specific_url': 'th/bang-phli/',\n",
       "  'latitude': '13.69 °N',\n",
       "  'longitude': '100.75 °E'},\n",
       " {'city_name': 'Ban Chang',\n",
       "  'province': 'Rayong',\n",
       "  'country': 'Thailand',\n",
       "  'station_name': 'U-Tapao International Airport Station',\n",
       "  'specific_url': 'th/ban-chang/',\n",
       "  'latitude': '12.72 °N',\n",
       "  'longitude': '101.05 °E'},\n",
       " {'city_name': 'Hai Chau',\n",
       "  'province': 'Da Nang',\n",
       "  'country': 'Vietnam',\n",
       "  'station_name': 'Da Nang International Airport Station',\n",
       "  'specific_url': 'vn/hai-chau/',\n",
       "  'latitude': '16.04 °N',\n",
       "  'longitude': '108.2 °E'},\n",
       " {'city_name': 'Siem Reap District',\n",
       "  'province': 'Siem Reap Province',\n",
       "  'country': 'Cambodia',\n",
       "  'station_name': 'Siem Reap International Airport Station',\n",
       "  'specific_url': 'kh/siem-reap-district/',\n",
       "  'latitude': '13.41 °N',\n",
       "  'longitude': '103.81 °E'},\n",
       " {'city_name': 'Phnom Penh',\n",
       "  'province': '',\n",
       "  'country': 'Cambodia',\n",
       "  'station_name': 'Phnom Penh International Airport Station',\n",
       "  'specific_url': 'kh/phnom-penh/',\n",
       "  'latitude': '11.55 °N',\n",
       "  'longitude': '104.84 °E'},\n",
       " {'city_name': 'Quận Tân Bình',\n",
       "  'province': 'Ho Chi Minh City',\n",
       "  'country': 'Vietnam',\n",
       "  'station_name': 'Tan Son Nhat International Airport Station',\n",
       "  'specific_url': 'vn/qu%E1%BA%ADn-t%C3%A2n-b%C3%ACnh/',\n",
       "  'latitude': '10.82 °N',\n",
       "  'longitude': '106.65 °E'},\n",
       " {'city_name': 'Soc Son',\n",
       "  'province': 'Hanoi',\n",
       "  'country': 'Vietnam',\n",
       "  'station_name': 'Noi Bai International Airport Station',\n",
       "  'specific_url': 'vn/soc-son/',\n",
       "  'latitude': '21.25 °N',\n",
       "  'longitude': '105.82 °E'},\n",
       " {'city_name': 'Yangon',\n",
       "  'province': 'Yangon Region',\n",
       "  'country': 'Myanmar',\n",
       "  'station_name': 'Yangon International Airport Station',\n",
       "  'specific_url': 'mm/yangon/',\n",
       "  'latitude': '16.99 °N',\n",
       "  'longitude': '96.14 °E'},\n",
       " {'city_name': 'Tada-U',\n",
       "  'province': 'Mandalay Region',\n",
       "  'country': 'Myanmar',\n",
       "  'station_name': 'Mandalay International Airport Station',\n",
       "  'specific_url': 'mm/tada-u/',\n",
       "  'latitude': '21.82 °N',\n",
       "  'longitude': '95.97 °E'},\n",
       " {'city_name': 'Chittagong',\n",
       "  'province': 'Chittagong',\n",
       "  'country': 'Bangladesh',\n",
       "  'station_name': 'Shah Amanat International Airport Station',\n",
       "  'specific_url': 'bd/chittagong/',\n",
       "  'latitude': '22.32 °N',\n",
       "  'longitude': '91.82 °E'},\n",
       " {'city_name': 'Dhaka',\n",
       "  'province': 'Dhaka Division',\n",
       "  'country': 'Bangladesh',\n",
       "  'station_name': 'Shahjalal International Airport Station',\n",
       "  'specific_url': 'bd/dhaka/',\n",
       "  'latitude': '23.7 °N',\n",
       "  'longitude': '90.37 °E'},\n",
       " {'city_name': 'Kunming',\n",
       "  'province': 'Yunnan',\n",
       "  'country': \"People's Republic of China\",\n",
       "  'station_name': 'Kunming Changshui International Airport Station',\n",
       "  'specific_url': 'cn/kunming/',\n",
       "  'latitude': '25.02 °N',\n",
       "  'longitude': '102.74 °E'},\n",
       " {'city_name': 'Sikhottabong',\n",
       "  'province': 'Vientiane',\n",
       "  'country': 'Laos',\n",
       "  'station_name': 'Wattay International Airport Station',\n",
       "  'specific_url': 'la/sikhottabong/',\n",
       "  'latitude': '18.01 °N',\n",
       "  'longitude': '102.48 °E'},\n",
       " {'city_name': 'Luang Prabang District',\n",
       "  'province': 'Luang Prabang Province',\n",
       "  'country': 'Laos',\n",
       "  'station_name': 'Luang Prabang International Airport Station',\n",
       "  'specific_url': 'la/luang-prabang-district/',\n",
       "  'latitude': '19.9 °N',\n",
       "  'longitude': '102.15 °E'},\n",
       " {'city_name': 'Namtha District',\n",
       "  'province': 'Luang Namtha Province',\n",
       "  'country': 'Laos',\n",
       "  'station_name': 'Luang Namtha Station',\n",
       "  'specific_url': 'la/namtha-district/',\n",
       "  'latitude': '21 °N',\n",
       "  'longitude': '101.45 °E'},\n",
       " {'city_name': 'Soc Son',\n",
       "  'province': 'Hanoi',\n",
       "  'country': 'Vietnam',\n",
       "  'station_name': 'Noi Bai International Airport Station',\n",
       "  'specific_url': 'vn/soc-son/',\n",
       "  'latitude': '21.25 °N',\n",
       "  'longitude': '105.82 °E'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add  East Jakarta\n"
     ]
    }
   ],
   "source": [
    "station_list = ['https://www.wunderground.com/history/daily/id/east-jakarta/WIHH/date/2020-8-22' ] \n",
    "add_weather_station(station_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Weather Data from OpenWeatherMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data \n",
    "city_name = 'East_Jakarta'\n",
    "final_filename = f'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/{city_name}.csv'\n",
    "try: \n",
    "    wea = pd.read_csv(filename)\n",
    "    wea['datetime'] = pd.to_datetime(wea['datetime'])\n",
    "    \n",
    "except:\n",
    "    wea = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'C:/Users/Benny/Documents/Fern/BKK-AQI/data/weather_cities/{city_name}/'\n",
    "files = glob(folder+'*.csv')\n",
    "# process data from OpenWeatherMap.org \n",
    "wea_df = pd.read_csv(files[0])\n",
    "wea_df = proc_open_weather(wea_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wea = pd.concat([wea_df,wea])\n",
    "new_wea = new_wea.sort_values(['datetime'],ignore_index=True)\n",
    "new_wea = new_wea.drop_duplicates('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Wind Speed(kmph)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Precip.(in)</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184130</th>\n",
       "      <td>2020-08-21 21:00:00</td>\n",
       "      <td>09:00 PM</td>\n",
       "      <td>26.28</td>\n",
       "      <td>78</td>\n",
       "      <td>E</td>\n",
       "      <td>16.560</td>\n",
       "      <td>29.82530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184131</th>\n",
       "      <td>2020-08-21 22:00:00</td>\n",
       "      <td>10:00 PM</td>\n",
       "      <td>26.09</td>\n",
       "      <td>78</td>\n",
       "      <td>E</td>\n",
       "      <td>16.560</td>\n",
       "      <td>29.82530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184132</th>\n",
       "      <td>2020-08-21 23:00:00</td>\n",
       "      <td>11:00 PM</td>\n",
       "      <td>25.94</td>\n",
       "      <td>78</td>\n",
       "      <td>ESE</td>\n",
       "      <td>12.960</td>\n",
       "      <td>29.82530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184133</th>\n",
       "      <td>2020-08-22 00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>25.19</td>\n",
       "      <td>83</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.400</td>\n",
       "      <td>29.79577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184134</th>\n",
       "      <td>2020-08-22 01:00:00</td>\n",
       "      <td>01:00 AM</td>\n",
       "      <td>24.71</td>\n",
       "      <td>83</td>\n",
       "      <td>S</td>\n",
       "      <td>9.360</td>\n",
       "      <td>29.79577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184135</th>\n",
       "      <td>2020-08-22 02:00:00</td>\n",
       "      <td>02:00 AM</td>\n",
       "      <td>24.25</td>\n",
       "      <td>83</td>\n",
       "      <td>S</td>\n",
       "      <td>9.360</td>\n",
       "      <td>29.82530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Haze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184136</th>\n",
       "      <td>2020-08-22 03:00:00</td>\n",
       "      <td>03:00 AM</td>\n",
       "      <td>23.74</td>\n",
       "      <td>94</td>\n",
       "      <td>ESE</td>\n",
       "      <td>12.708</td>\n",
       "      <td>29.85483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Haze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184137</th>\n",
       "      <td>2020-08-22 04:00:00</td>\n",
       "      <td>04:00 AM</td>\n",
       "      <td>23.50</td>\n",
       "      <td>94</td>\n",
       "      <td>ESE</td>\n",
       "      <td>12.708</td>\n",
       "      <td>29.82530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Haze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184138</th>\n",
       "      <td>2020-08-22 05:00:00</td>\n",
       "      <td>05:00 AM</td>\n",
       "      <td>23.14</td>\n",
       "      <td>94</td>\n",
       "      <td>ESE</td>\n",
       "      <td>12.708</td>\n",
       "      <td>29.85483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Haze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184139</th>\n",
       "      <td>2020-08-22 06:00:00</td>\n",
       "      <td>06:00 AM</td>\n",
       "      <td>24.10</td>\n",
       "      <td>94</td>\n",
       "      <td>ESE</td>\n",
       "      <td>13.896</td>\n",
       "      <td>29.85483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Haze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime      Time  Temperature(C)  Humidity(%) Wind  \\\n",
       "184130 2020-08-21 21:00:00  09:00 PM           26.28           78    E   \n",
       "184131 2020-08-21 22:00:00  10:00 PM           26.09           78    E   \n",
       "184132 2020-08-21 23:00:00  11:00 PM           25.94           78  ESE   \n",
       "184133 2020-08-22 00:00:00  12:00 AM           25.19           83   SE   \n",
       "184134 2020-08-22 01:00:00  01:00 AM           24.71           83    S   \n",
       "184135 2020-08-22 02:00:00  02:00 AM           24.25           83    S   \n",
       "184136 2020-08-22 03:00:00  03:00 AM           23.74           94  ESE   \n",
       "184137 2020-08-22 04:00:00  04:00 AM           23.50           94  ESE   \n",
       "184138 2020-08-22 05:00:00  05:00 AM           23.14           94  ESE   \n",
       "184139 2020-08-22 06:00:00  06:00 AM           24.10           94  ESE   \n",
       "\n",
       "        Wind Speed(kmph)  Pressure(in)  Precip.(in) Condition  \n",
       "184130            16.560      29.82530          0.0    Clouds  \n",
       "184131            16.560      29.82530          0.0    Clouds  \n",
       "184132            12.960      29.82530          0.0    Clouds  \n",
       "184133             5.400      29.79577          0.0    Clouds  \n",
       "184134             9.360      29.79577          0.0    Clouds  \n",
       "184135             9.360      29.82530          0.0      Haze  \n",
       "184136            12.708      29.85483          0.0      Haze  \n",
       "184137            12.708      29.82530          0.0      Haze  \n",
       "184138            12.708      29.85483          0.0      Haze  \n",
       "184139            13.896      29.85483          0.0      Haze  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wea[new_wea['datetime'] > '2019-01-01'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wea.to_csv(final_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holiday In Thailand\n",
    "\n",
    "https://www.timeanddate.com/holidays/thailand/2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2000,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape holiday from all websites\n",
    "th_holiday = pd.DataFrame()\n",
    "for year in years:\n",
    "    url = f'https://www.timeanddate.com/holidays/thailand/{year}'\n",
    "    df = pd.read_html(url)[0]\n",
    "    df['year'] = year\n",
    "    th_holiday = pd.concat([th_holiday,df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday.columns = ['Date', 'day_of_week','name','type','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday = th_holiday[~th_holiday['Date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday['date'] = th_holiday['Date'] + ', ' + th_holiday['year'].astype(str)\n",
    "th_holiday['date'] = pd.to_datetime(th_holiday['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/th_holiday.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotspots Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stationID': '36t', 'nameTH': 'โรงเรียนยุพราชวิทยาลัย ', 'nameEN': 'Yupparaj Wittayalai School', 'areaTH': 'ต.ศรีภูมิ อ.เมือง, เชียงใหม่', 'areaEN': 'Si Phum, Meuang, Chiang Mai', 'stationType': 'GROUND', 'lat': '18.7909205', 'long': '98.9881062', 'LastUpdate': {'date': '2020-03-27', 'time': '03:00', 'PM25': {'value': '87', 'unit': 'µg/m³'}, 'PM10': {'value': '110', 'unit': 'µg/m³'}, 'O3': {'value': 'N/A', 'unit': 'ppb'}, 'CO': {'value': '1.09', 'unit': 'ppm'}, 'NO2': {'value': '-', 'unit': 'ppb'}, 'SO2': {'value': '2', 'unit': 'ppb'}, 'AQI': {'Level': '4', 'aqi': '192'}}}\n"
     ]
    }
   ],
   "source": [
    "# load stations information for Chiangmai\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "print(station_info[124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117.0 11019.0\n"
     ]
    }
   ],
   "source": [
    "# obtain the lat and long in km\n",
    "lat_km = (merc_y(station_info[124]['lat'])/1E3 ).round()\n",
    "long_km = (merc_x(station_info[124]['long'])/1E3).round()\n",
    "print(lat_km,  long_km )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file map folder \n",
    "m_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6/*.csv')\n",
    "v_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/V1/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [13:35<00:00, 38.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "\n",
    "\n",
    "file_all = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(m_files):\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "     \n",
    "    file_all = pd.concat([file_all,f],ignore_index=True)\n",
    "        \n",
    "        \n",
    "file_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3242: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop (3901918, 18)\n",
      "after drop (3829241, 18)\n"
     ]
    }
   ],
   "source": [
    "m_filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "process_fire_data(m_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv'\n",
    "\n",
    "fire_all = pd.DataFrame()\n",
    "\n",
    "for file in v_files:\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round()\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round()\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "    \n",
    "    fire_all = pd.concat([fire_all,f],ignore_index=True)  \n",
    "     \n",
    "        \n",
    "fire_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (10,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'bright_ti4', 'scan', 'track', 'acq_date',\n",
       "       'acq_time', 'satellite', 'instrument', 'confidence', 'version',\n",
       "       'bright_ti5', 'frp', 'type', 'lat_km', 'long_km', 'daynight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop (9092222, 18)\n",
      "after drop (6925015, 18)\n"
     ]
    }
   ],
   "source": [
    "process_fire_data('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire For Chiang Mai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3779468, 10)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['year' 'season'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-be2f93342166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'power'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'track'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'frp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'brightness'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'season'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'acq_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'track'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'scan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'frp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m_proc.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3993\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3994\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3995\u001b[0m         )\n\u001b[0;32m   3996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3933\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3934\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3935\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3967\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3968\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3969\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3970\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['year' 'season'] not found in axis\""
     ]
    }
   ],
   "source": [
    "city_info = {'Country': 'Thailand',\n",
    " 'City': 'Chiang Mai',\n",
    " 'City (ASCII)': 'Chiang Mai',\n",
    " 'Region': 'Chiang Mai',\n",
    " 'Region (ASCII)': 'Chiang Mai',\n",
    " 'Population': '200952',\n",
    " 'Latitude': '18.7904',\n",
    " 'Longitude': '98.9847',\n",
    " 'Time Zone': 'Asia/Bangkok'}\n",
    "\n",
    "x = merc_x(city_info['Longitude'])\n",
    "y = merc_y(city_info['Latitude'])\n",
    "stepx = 800E3\n",
    "stepy = stepx\n",
    "\n",
    "#fire_v = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')\n",
    "m_filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "fire = pd.read_csv(m_filename, dtype={'version': str})\n",
    "columns_to_drop = ['acq_date','satellite','instrument','version','daynight','bright_t31','type']\n",
    "fire = fire.drop(columns_to_drop,axis=1)\n",
    "fire['datetime'] = pd.to_datetime(fire['datetime'])\n",
    "fire = fire.sort_values('datetime')\n",
    "fire = fire.set_index('datetime')\n",
    "# remove the data before '2002-07-04' because there is only one satellite\n",
    "fire = fire.loc['2002-07-04':]\n",
    "print(fire.shape)\n",
    "\n",
    "\n",
    "# add distance columns\n",
    "fire['distance'] = np.sqrt((fire['lat_km'] - y/1000) **2 + ((fire['long_km'] - x/1000)**2))\n",
    "\n",
    "# create power column and drop unncessary columns\n",
    "fire['power'] = fire['scan']*fire['track']*fire['frp']\n",
    "fire['count'] = 1\n",
    "fire = fire.drop(['latitude', 'longitude', 'brightness','year','season','acq_time','track','scan','frp'], axis=1)\n",
    "fire.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m_proc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impove Speed of Files reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_km = 2117.0 \n",
    "long_km = 11019.0\n",
    "m_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [16:11<00:00, 44.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# check the time without threading  \n",
    "file_all = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(m_files):\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "     \n",
    "    file_all = pd.concat([file_all,f],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_fire(file,lat_km, long_km):\n",
    "   \n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "    # remove by long \n",
    "    f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "    return f\n",
    " \n",
    "\n",
    "def read_fire_dd(file,lat_km, long_km):\n",
    "   \n",
    "    f = dd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "    # remove by long \n",
    "    f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "    return f\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_fires(files,lat_km, long_km):\n",
    "    \n",
    "    all_fire = pd.DataFrame()\n",
    "    for file in files:\n",
    "        if file != None:\n",
    "            f = pd.read_csv(file)\n",
    "     \n",
    "            # convert lat \n",
    "            f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "            f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "            # remove by lat \n",
    "            f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "            # remove by long \n",
    "            f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "            all_fire = pd.concat([all_fire, f], ignore_index=True)\n",
    "    return all_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229176, 17)\n",
      "(235249, 17)\n",
      "(214976, 17)\n",
      "(234913, 17)\n",
      "(165272, 17)\n",
      "(288160, 17)\n",
      "(230523, 17)\n",
      "(176189, 17)\n",
      "(276734, 17)\n",
      "(198856, 17)\n",
      "(225431, 17)\n",
      "(276406, 17)\n",
      "(7802, 17)\n",
      "(2898, 17)\n",
      "(195966, 17)\n",
      "(45055, 17)\n",
      "(210563, 17)\n",
      "(198697, 17)\n",
      "(142868, 17)\n",
      "(155097, 17)\n",
      "(49102, 16)\n",
      "(149221, 17)\n",
      "Wall time: 13min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try with threadpoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    future_list = [executor.submit(read_fire, file, lat_km, long_km) for file in m_files]\n",
    "    fire_all = pd.DataFrame()\n",
    "    for future in concurrent.futures.as_completed(future_list):\n",
    "        df = future.result()\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251721, 17)\n",
      "(860144, 17)\n",
      "(914314, 17)\n",
      "(204199, 17)\n",
      "(977427, 17)\n",
      "(701349, 17)\n",
      "Wall time: 17min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    future_list = [executor.submit(read_fires, group, lat_km, long_km) for group in grouper(m_files, 4)]\n",
    "    fire_all = pd.DataFrame()\n",
    "    for future in concurrent.futures.as_completed(future_list):\n",
    "        df = future.result()\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6\\\\fire_archive_M6_100871.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(m_files[0])\n",
    "df['lat_km'] = (df['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "df['long_km'] = (merc_x(df['longitude'])/1E3).round().astype(int)\n",
    "# remove by lat \n",
    "df = df[(df['lat_km'] <= (lat_km+1000)) & (df['lat_km'] >= (lat_km-1000))]\n",
    "# remove by long \n",
    "df = df[(df['long_km'] <= (long_km+1000)) & (df['long_km'] >= (long_km-1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>brightness</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_t31</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>type</th>\n",
       "      <th>lat_km</th>\n",
       "      <th>long_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>23.4521</td>\n",
       "      <td>107.8448</td>\n",
       "      <td>307.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>410</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>66</td>\n",
       "      <td>6.2</td>\n",
       "      <td>286.6</td>\n",
       "      <td>49.5</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>23.4631</td>\n",
       "      <td>107.8534</td>\n",
       "      <td>304.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>410</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>58</td>\n",
       "      <td>6.2</td>\n",
       "      <td>286.7</td>\n",
       "      <td>37.4</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2671</td>\n",
       "      <td>12006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>21.6968</td>\n",
       "      <td>103.0861</td>\n",
       "      <td>318.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>79</td>\n",
       "      <td>6.2</td>\n",
       "      <td>291.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2459</td>\n",
       "      <td>11475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>21.6998</td>\n",
       "      <td>103.0696</td>\n",
       "      <td>309.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>69</td>\n",
       "      <td>6.2</td>\n",
       "      <td>292.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2460</td>\n",
       "      <td>11474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>22.1135</td>\n",
       "      <td>101.1773</td>\n",
       "      <td>305.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>61</td>\n",
       "      <td>6.2</td>\n",
       "      <td>289.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2509</td>\n",
       "      <td>11263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     latitude  longitude  brightness  scan  track    acq_date  acq_time  \\\n",
       "259   23.4521   107.8448       307.5   3.4    1.7  2015-01-01       410   \n",
       "260   23.4631   107.8534       304.2   3.4    1.7  2015-01-01       410   \n",
       "261   21.6968   103.0861       318.7   1.7    1.3  2015-01-01       411   \n",
       "262   21.6998   103.0696       309.5   1.7    1.3  2015-01-01       411   \n",
       "263   22.1135   101.1773       305.3   1.3    1.1  2015-01-01       411   \n",
       "\n",
       "    satellite instrument  confidence  version  bright_t31   frp daynight  \\\n",
       "259     Terra      MODIS          66      6.2       286.6  49.5        D   \n",
       "260     Terra      MODIS          58      6.2       286.7  37.4        D   \n",
       "261     Terra      MODIS          79      6.2       291.9  35.2        D   \n",
       "262     Terra      MODIS          69      6.2       292.6  19.3        D   \n",
       "263     Terra      MODIS          61      6.2       289.2   9.1        D   \n",
       "\n",
       "     type  lat_km  long_km  \n",
       "259     0    2670    12005  \n",
       "260     0    2671    12006  \n",
       "261     0    2459    11475  \n",
       "262     0    2460    11474  \n",
       "263     0    2509    11263  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try with dask\n",
    "all_fire = [read_fire_dd(file,lat_km, long_km) for file in m_files]\n",
    "all_fire = dd.concat(all_fire)\n",
    "fire_df = all_fire.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))\n",
    "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_fire_list = Parallel(n_jobs=2)(delayed(read_fire)(file, lat_km, long_km) for file in m_files)\n",
    "fire_df = pd.concat(all_fire_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data From Hanoi US Embassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 389775 / 389775"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/us_emb/Hanoi_PM2.5_2020_YTD (1).csv'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('http://dosairnowdata.org/dos/historical/Hanoi/2020/Hanoi_PM2.5_2020_YTD.csv','../data/us_emb/Hanoi_PM2.5_2020_YTD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-192a73e779c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://traffic.longdo.com/trafficdaily?sort=peak'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m         \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[0mretained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"bs4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html5lib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"html5lib not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BeautifulSoup4 (bs4) not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "df = pd.read_html('https://traffic.longdo.com/trafficdaily?sort=peak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnam EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of station 33. Takes about 1 mins per station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [25:34<00:00, 46.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total data has len 796\n",
      "save file as  C:\\Users\\Benny\\Documents\\Fern\\aqi_thailand2\\data\\vn_epa\\2020-08-31_19-20.csv\n",
      "Wall time: 27min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data, station_info_list  = download_vn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.175px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
