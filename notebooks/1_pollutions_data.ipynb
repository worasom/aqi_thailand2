{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Source\" data-toc-modified-id=\"Data-Source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Source</a></span></li><li><span><a href=\"#Imports-and-Update-The-Latest-Data\" data-toc-modified-id=\"Imports-and-Update-The-Latest-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports and Update The Latest Data</a></span></li><li><span><a href=\"#Historical-air-4-Thai-Data\" data-toc-modified-id=\"Historical-air-4-Thai-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Historical air 4 Thai Data</a></span></li><li><span><a href=\"#Power-Plants\" data-toc-modified-id=\"Power-Plants-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Power Plants</a></span></li><li><span><a href=\"#Weather-Files\" data-toc-modified-id=\"Weather-Files-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Weather Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Assemble-from-raw-data\" data-toc-modified-id=\"Assemble-from-raw-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Assemble from raw data</a></span></li><li><span><a href=\"#Update-weather-all-cities\" data-toc-modified-id=\"Update-weather-all-cities-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Update weather all cities</a></span></li></ul></li><li><span><a href=\"#Holiday-In-Thailand\" data-toc-modified-id=\"Holiday-In-Thailand-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Holiday In Thailand</a></span></li><li><span><a href=\"#Hotspots-Data\" data-toc-modified-id=\"Hotspots-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hotspots Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fire-For-Chiang-Mai\" data-toc-modified-id=\"Fire-For-Chiang-Mai-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Fire For Chiang Mai</a></span></li><li><span><a href=\"#Impove-Speed-of-Files-reading\" data-toc-modified-id=\"Impove-Speed-of-Files-reading-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Impove Speed of Files reading</a></span></li></ul></li><li><span><a href=\"#Merge-Weather-Data-from-OpenWeatherMap\" data-toc-modified-id=\"Merge-Weather-Data-from-OpenWeatherMap-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Merge Weather Data from OpenWeatherMap</a></span></li><li><span><a href=\"#Data-From-Hanoi-US-Embassy\" data-toc-modified-id=\"Data-From-Hanoi-US-Embassy-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Data From Hanoi US Embassy</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source \n",
    "1. Berekely Earth 'http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/'\n",
    "2. Screaped Air4Thai Data 'http://air4thai.pcd.go.th/webV2/history/'\n",
    "3. CDC Data 'https://www.cmuccdc.org/download_json/'\n",
    "4. Old Air4Thai data from Thailand EPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Update The Latest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pollution data from 3 sources and update weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#  Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "from pathlib import Path\n",
    "\n",
    "#  always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.imports import *\n",
    "from src.data.download_data import *\n",
    "from src.data.read_data import *\n",
    "from src.data.fire_data import *\n",
    "from src.data.weather_data import *\n",
    "from src.gen_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_folder='../data/pm25/'\n",
    "a4th_folder='../data/air4thai_hourly/'\n",
    "cm_folder ='../data/cm_proc/'\n",
    "cdc_folder = '../data/cdc_data/'\n",
    "aqm_folder = '../data/aqm_hourly2/'\n",
    "w_folder = '../data/weather_cities/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download Berkeley PM2.5 data for all files in http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/\n",
      "100% [............................................................................] 823834 / 823834\n",
      " Download Data for Hanoi, Ha dong and Jarkata\n",
      "100% [............................................................................] 763778 / 763778\n",
      " Download us embassy data for Hanoi and Jakata for 2020\n",
      "100% [............................................................................] 409852 / 409852download more pollution data from Thailand PCD\n",
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [30:03, 21.99s/it]\n",
      "  0%|                                                                                                              | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weather data for all cities\n",
      "update weather data for  Mueang Chiang Mai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:34, 34.89s/it]\u001b[A\n",
      "2it [01:09, 34.95s/it]\u001b[A\n",
      "3it [01:39, 33.21s/it]\u001b[A\n",
      "4it [02:08, 32.00s/it]\u001b[A\n",
      "5it [02:37, 31.15s/it]\u001b[A\n",
      "6it [03:09, 31.49s/it]\u001b[A\n",
      "7it [04:42, 40.36s/it]\u001b[A\n",
      "  9%|█████████▏                                                                                           | 1/11 [04:59<49:59, 299.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:38, 38.44s/it]\u001b[A\n",
      "2it [01:25, 40.91s/it]\u001b[A\n",
      "3it [02:03, 40.13s/it]\u001b[A\n",
      "4it [02:43, 40.16s/it]\u001b[A\n",
      "5it [03:19, 38.94s/it]\u001b[A\n",
      "6it [03:53, 37.45s/it]\u001b[A\n",
      "7it [04:32, 39.00s/it]\u001b[A\n",
      " 18%|██████████████████▎                                                                                  | 2/11 [09:45<44:20, 295.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████████████▌                                                                         | 3/11 [09:47<27:39, 207.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing date 0\n",
      "update weather data for  Bangkok\n",
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:35, 35.27s/it]\u001b[A\n",
      "2it [01:08, 34.72s/it]\u001b[A\n",
      "3it [01:41, 34.11s/it]\u001b[A\n",
      "4it [02:14, 33.78s/it]\u001b[A\n",
      "5it [02:42, 32.08s/it]\u001b[A\n",
      "6it [04:13, 49.81s/it]\u001b[A\n",
      "7it [04:44, 40.70s/it]\u001b[A\n",
      " 36%|████████████████████████████████████▋                                                                | 4/11 [14:47<27:26, 235.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Chiang Rai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:33, 93.91s/it]\u001b[A\n",
      "2it [03:06, 93.41s/it]\u001b[A\n",
      "3it [03:36, 74.42s/it]\u001b[A\n",
      "4it [04:06, 61.02s/it]\u001b[A\n",
      "5it [04:34, 51.33s/it]\u001b[A\n",
      "6it [05:04, 44.88s/it]\u001b[A\n",
      "7it [05:33, 47.65s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████████████▉                                                       | 5/11 [20:35<26:55, 269.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Tak\n",
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:37, 37.51s/it]\u001b[A\n",
      "2it [01:08, 35.44s/it]\u001b[A\n",
      "3it [01:38, 34.01s/it]\u001b[A\n",
      "4it [02:08, 32.86s/it]\u001b[A\n",
      "5it [02:44, 33.53s/it]\u001b[A\n",
      "6it [03:14, 32.67s/it]\u001b[A\n",
      "7it [03:48, 32.67s/it]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████                                              | 6/11 [24:39<21:47, 261.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Yangon\n",
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:35, 35.27s/it]\u001b[A\n",
      "2it [01:11, 35.63s/it]\u001b[A\n",
      "3it [01:43, 34.46s/it]\u001b[A\n",
      "4it [02:18, 34.59s/it]\u001b[A\n",
      "5it [02:54, 35.05s/it]\u001b[A\n",
      "6it [03:26, 34.11s/it]\u001b[A\n",
      "7it [03:57, 33.94s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████████████████▎                                    | 7/11 [28:51<17:14, 258.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Tada-U\n",
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:34, 34.56s/it]\u001b[A\n",
      "2it [01:04, 33.05s/it]\u001b[A\n",
      "3it [01:33, 31.86s/it]\u001b[A\n",
      "4it [02:02, 31.00s/it]\u001b[A\n",
      "5it [02:35, 31.71s/it]\u001b[A\n",
      "6it [03:09, 32.24s/it]\u001b[A\n",
      "7it [03:37, 31.06s/it]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████████████████████████▍                           | 8/11 [32:43<12:32, 250.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Sikhottabong\n",
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:36, 36.62s/it]\u001b[A\n",
      "2it [01:12, 36.47s/it]\u001b[A\n",
      "3it [01:43, 34.72s/it]\u001b[A\n",
      "4it [02:21, 35.66s/it]\u001b[A\n",
      "5it [02:51, 34.05s/it]\u001b[A\n",
      "6it [03:21, 32.89s/it]\u001b[A\n",
      "7it [04:55, 42.20s/it]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████▋                  | 9/11 [37:54<08:57, 268.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Luang Prabang District\n",
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:34, 34.70s/it]\u001b[A\n",
      "2it [01:04, 33.17s/it]\u001b[A\n",
      "3it [01:33, 31.91s/it]\u001b[A\n",
      "4it [02:03, 31.29s/it]\u001b[A\n",
      "5it [02:32, 30.60s/it]\u001b[A\n",
      "6it [03:06, 31.59s/it]\u001b[A\n",
      "7it [03:35, 31.01s/it]\u001b[A\n",
      "8it [04:08, 31.70s/it]\u001b[A\n",
      "9it [04:41, 32.05s/it]\u001b[A\n",
      "10it [05:14, 32.22s/it]\u001b[A\n",
      "11it [05:47, 31.64s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████▉         | 10/11 [43:57<04:57, 297.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Kunming\n",
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:35, 35.05s/it]\u001b[A\n",
      "2it [01:07, 34.33s/it]\u001b[A\n",
      "3it [01:40, 33.78s/it]\u001b[A\n",
      "4it [03:11, 51.17s/it]\u001b[A\n",
      "5it [03:44, 45.49s/it]\u001b[A\n",
      "6it [04:16, 41.49s/it]\u001b[A\n",
      "7it [05:48, 49.78s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [50:01<00:00, 272.85s/it]\n"
     ]
    }
   ],
   "source": [
    "main(cdc_data=False, build_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download Berkeley PM2.5 data for all files in http://berkeleyearth.lbl.gov/air-quality/maps/cities/Thailand/\n",
      "100% [............................................................................] 823834 / 823834\n",
      " Download Data for Hanoi, Ha dong and Jarkata\n",
      "100% [............................................................................] 763778 / 763778\n",
      " Download us embassy data for Hanoi and Jakata for 2020\n",
      "100% [............................................................................] 409852 / 409852download more pollution data from Thailand PCD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [30:34, 22.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download data from Chiang Mai University Project (CDC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                             | 0/404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stations 433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 404/404 [17:52<00:00,  2.65s/it]\n",
      "  0%|                                                                                                              | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weather data for all cities\n",
      "update weather data for  Mueang Chiang Mai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:28, 28.93s/it]\u001b[A\n",
      "2it [00:57, 28.69s/it]\u001b[A\n",
      "  9%|█████████▎                                                                                            | 1/11 [01:13<12:11, 73.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:31, 31.64s/it]\u001b[A\n",
      "2it [01:02, 31.30s/it]\u001b[A\n",
      " 18%|██████████████████▌                                                                                   | 2/11 [02:28<11:03, 73.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Soc Son\n",
      "updateing file: ../data/weather_cities/Soc_Son.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████████████▊                                                                          | 3/11 [02:29<06:56, 52.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing date 0\n",
      "update weather data for  Bangkok\n",
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:27, 27.72s/it]\u001b[A\n",
      "2it [00:55, 27.53s/it]\u001b[A\n",
      " 36%|█████████████████████████████████████                                                                 | 4/11 [03:40<06:42, 57.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Chiang Rai\n",
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:29, 29.17s/it]\u001b[A\n",
      "2it [00:57, 28.80s/it]\u001b[A\n",
      " 45%|██████████████████████████████████████████████▎                                                       | 5/11 [04:52<06:12, 62.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Mueang Tak\n",
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:30, 30.56s/it]\u001b[A\n",
      "2it [01:00, 30.09s/it]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████▋                                              | 6/11 [06:07<05:30, 66.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Yangon\n",
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:30, 30.58s/it]\u001b[A\n",
      "2it [01:06, 33.02s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████████████████▉                                     | 7/11 [07:28<04:41, 70.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Tada-U\n",
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:28, 28.68s/it]\u001b[A\n",
      "2it [01:03, 31.54s/it]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████▏                           | 8/11 [08:47<03:38, 72.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Sikhottabong\n",
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:30, 30.12s/it]\u001b[A\n",
      "2it [00:59, 29.83s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████████████████████▍                  | 9/11 [10:02<02:26, 73.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Luang Prabang District\n",
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:33, 33.91s/it]\u001b[A\n",
      "2it [01:09, 34.27s/it]\u001b[A\n",
      "3it [01:41, 33.62s/it]\u001b[A\n",
      "4it [02:13, 33.24s/it]\u001b[A\n",
      "5it [02:45, 32.79s/it]\u001b[A\n",
      "6it [03:17, 32.73s/it]\u001b[A\n",
      "7it [03:47, 32.49s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████▉         | 10/11 [14:04<02:04, 124.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update weather data for  Kunming\n",
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:28, 28.04s/it]\u001b[A\n",
      "2it [00:55, 27.98s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [15:15<00:00, 83.27s/it]\n"
     ]
    }
   ],
   "source": [
    "main(cdc_data=True, build_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                             | 0/404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stations 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 404/404 [39:15<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "download_cdc_data(station_url='https://www.cmuccdc.org/api/ccdc/stations', \n",
    "                  dl_url= 'https://www.cmuccdc.org/download_json/', \n",
    "                  data_folder='../data/cdc_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02t', '03t', '05t', '08t', '10t', '11t', '12t', '13t', '14t', '16t', '17t', '18t', '19t', '20t', '21t', '22t', '24t', '25t', '26t', '27t', '28t', '29t', '30t', '31t', '32t', '33t', '34t', '35t', '36t', '37t', '38t', '39t', '40t', '41t', '42t', '43t', '44t', '46t', '47t', '50t', '52t', '53t', '54t', '57t', '58t', '59t', '60t', '61t', '62t', '63t', '67t', '68t', '69t', '70t', '71t', '72t', '73t', '74t', '75t', '76t', '77t', '79t', '80t', '81t', '82t', '83t', '84t', 'm1', 'm3', 'm4', 'm8', 'm9', 'o10', 'o20', 'o22', 'o23', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [13:48, 18.85s/it]"
     ]
    }
   ],
   "source": [
    "update_last_air4Thai(url='http://air4thai.pcd.go.th/webV2/history/',data_folder='../data/air4thai_hourly/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update weather data \n",
    "\n",
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Soc Son', 'Bangkok', 'Mueang Chiang Rai', 'Mueang Tak','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)\n",
    "\n",
    "for city_json in tqdm(weather_station_info):\n",
    "    \n",
    "    start_date = datetime(2020,1,1)\n",
    "    end_date = datetime.now()\n",
    "    update_weather(city_json, data_folder=w_folder, start_date=start_date, end_date=end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical air 4 Thai Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35t', '36t', 'm9', 'o10', 'o20', 'o22']\n"
     ]
    }
   ],
   "source": [
    "# load stations information for air4 Thai\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "# find stations in Chiangmai and parase that files\n",
    "cm_station_ids = []\n",
    "cm_station_info = []\n",
    "for i, stations in enumerate(station_info):\n",
    "    if 'Chiang Mai' in stations['areaEN']:\n",
    "        cm_station_ids.append(stations['stationID'])\n",
    "        cm_station_info.append(stations)\n",
    "print(cm_station_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save filename ../data/aqm_hourly2/process/35t.csv\n",
      "save filename ../data/aqm_hourly2/process/36t.csv\n"
     ]
    }
   ],
   "source": [
    "# parase historical data \n",
    "for station_id in cm_station_ids:\n",
    "    # find all files that start with this stations\n",
    "    p = Path(aqm_folder)\n",
    "    filenames = []\n",
    "    for i in p.glob('**/*.xlsx'):\n",
    "        if station_id in i.name:\n",
    "            filenames.append(str(i))\n",
    "        \n",
    "    # if filename exist load that file\n",
    "    if len(filenames) >0:\n",
    "\n",
    "        save_filename = aqm_folder + 'process/' + station_id + '.csv'\n",
    "        print('save filename', save_filename)\n",
    "        station_data = read_his_xl(filenames[0])\n",
    "        #print(station_data.head())\n",
    "\n",
    "        # save the data if the dataframe is not empty\n",
    "        if len(station_data)> 0:\n",
    "            station_data.to_csv(save_filename,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cm_proc/35t.csv\n",
      "../data/cm_proc/36t.csv\n",
      "../data/cm_proc/m9.csv\n",
      "../data/cm_proc/o10.csv\n",
      "../data/cm_proc/o20.csv\n",
      "../data/cm_proc/o22.csv\n"
     ]
    }
   ],
   "source": [
    "# combine new and old air4Thai data \n",
    "gas_cols = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5']\n",
    "for station_id in cm_station_ids:\n",
    "    try: \n",
    "        old_data = pd.read_csv(aqm_folder + 'process/'+station_id + '.csv')\n",
    "    except:\n",
    "        old_data = pd.DataFrame()\n",
    "    else:\n",
    "        old_data['datetime'] = pd.to_datetime(old_data['datetime'])\n",
    "        old_data = old_data.set_index('datetime')\n",
    "        # keep only the gass columns\n",
    "        old_data = old_data[gas_cols]\n",
    "    \n",
    "    new_data = pd.read_csv(a4th_folder + station_id + '.csv',na_values='-').set_index('datetime')\n",
    "    new_data.columns = [s.split(' (')[0] for s in new_data.columns]\n",
    "    # keep only the gass columns\n",
    "    new_data = new_data[gas_cols]\n",
    "    # concatinate data and save\n",
    "    data = pd.concat([old_data,new_data])\n",
    "    filename = cm_folder+station_id + '.csv'\n",
    "    print(filename)\n",
    "    data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data1 = pd.read_csv(aqm_folder + 'process/35t.csv')\n",
    "cm_data1['datetime'] = pd.to_datetime(cm_data1['datetime'])\n",
    "cm_data1 = cm_data1.set_index('datetime')\n",
    "# keep only gas columns\n",
    "cm_data1 = cm_data1[['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5']]\n",
    "\n",
    "cm_data2 = pd.read_csv(aqm_folder + 'process/36t.csv')\n",
    "cm_data2['datetime'] = pd.to_datetime(cm_data2['datetime'])\n",
    "cm_data2 = cm_data2.set_index('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour   CO  NO NO2 SO2  NOX      Pressure           Rain  \\\n",
      "0  960101   100  2.6  51  32   5   83                                \n",
      "1  960101   200  2.8  71  30   6  101                                \n",
      "2  960101   300  2.8  75  29   6  104                                \n",
      "3  960101   400  2.5  52  25   5   78                                \n",
      "4  960101   500  1.4  17  21   5   39                                \n",
      "\n",
      "        Rel hum          Temp      Wind dir     Wind speed            CO8  \n",
      "0                                                                          \n",
      "1                                                                    2.45  \n",
      "2                                                                 2.25714  \n",
      "3                                                                  2.1125  \n",
      "4                                                                   1.975  \n",
      "    date  hour        CO  NO            O3 NO2 SO2 NOX PM10 PM2.5 Pressure  \\\n",
      "0  30101   100      1.73  16                38   4  53  NaN   NaN     29.9   \n",
      "1  30101   200      1.79  16                36   3  52  NaN   NaN     29.9   \n",
      "2  30101   300      1.38  12                32   2  44  NaN   NaN     29.9   \n",
      "3  30101   400  0.639999   5                24   2  29  NaN   NaN     29.9   \n",
      "4  30101   500      0.57   4                26   3  30  NaN   NaN     29.9   \n",
      "\n",
      "  Rain  Rel hum  Temp Wind dir Wind speed       CO8  \n",
      "0    0     68.6  27.9      289       1.36      1.07  \n",
      "1    0  68.7999  27.9      341        1.5   1.04625  \n",
      "2    0       69  27.8       13       1.32      1.02  \n",
      "3    0     66.1  27.9       94       1.56  0.982499  \n",
      "4    0     70.5  27.4      115       1.59  0.993749  \n",
      "     date  hour CO SO2 NO NO2 NOX Wind speed Wind dir  Temp  ... Unnamed: 27  \\\n",
      "0  100101   100  -   0  1  13  14       1.37      213  28.4  ...         NaN   \n",
      "1  100101   200  -   0  0  14  15       1.42      218  28.1  ...         NaN   \n",
      "2  100101   300  -   0  2  19  20       1.27      213  27.9  ...         NaN   \n",
      "3  100101   400  -   0  1  18  19       1.12      225  27.8  ...         NaN   \n",
      "4  100101   500  -   1  2  20  22       0.98      247  27.7  ...         NaN   \n",
      "\n",
      "  Unnamed: 28 Unnamed: 29 Unnamed: 30 Unnamed: 31  Unnamed: 32  Unnamed: 33  \\\n",
      "0         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "1         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "2         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "3         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "4         NaN         NaN         NaN         NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 34  Unnamed: 35  Unnamed: 36  \n",
      "0          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "     date  hour CO SO2 NO NO2 PM10 O3 PM2.5\n",
      "0  130101   100  -   -  -   -    -  -   NaN\n",
      "1  130101   200  -   -  -   -    -  -   NaN\n",
      "2  130101   300  -   -  -   -    -  -   NaN\n",
      "3  130101   400  -   -  -   -    -  -   NaN\n",
      "4  130101   500  -   -  -   -    -  -   NaN\n",
      "     date  hour CO NO2 Temp O3 PM10 PM2.5\n",
      "0  170301   100  -   -    -  -    -   NaN\n",
      "1  170301   200  -   -    -  -    -   NaN\n",
      "2  170301   300  -   -    -  -    -   NaN\n",
      "3  170301   400  -   -    -  -    -   NaN\n",
      "4  170301   500  -   -    -  -    -   NaN\n",
      "     date  hour CO O3 NO2 SO2\n",
      "0  960101   100  1  6  36   3\n",
      "1  960101   200  1  4  41   2\n",
      "2  960101   300  1  4  39   2\n",
      "3  960101   400  1  4  39   3\n",
      "4  960101   500  1  4  40   5\n",
      "    date  hour   CO  O3 NO2 SO2 PM10\n",
      "0  30101   100  1.1   5  33   5  NaN\n",
      "1  30101   200  1.1   4  36   6  NaN\n",
      "2  30101   300  0.5   6  28   4  NaN\n",
      "3  30101   400  0.3   8  21   3  NaN\n",
      "4  30101   500    0  12  14   3  NaN\n",
      "     date  hour   CO SO2 NO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.5   3  12  11   34   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.4   3   9  13   27   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.4   3  11  12   25   NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.5   3  12  11   24   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.6   4  13  10   31   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "     date  hour   CO SO2 NO2  O3 PM10 PM2.5\n",
      "0  170101   100  0.4   1   2  24   45    44\n",
      "1  170101   200  0.3   1   0  26   58    48\n",
      "2  170101   300  0.3   1   0  26   37    36\n",
      "3  170101   400  0.3   1   0  29   37    35\n",
      "4  170101   500  0.3   0   0  27   39    37\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO  O3 NO2 SO2 PM10\n",
      "0  30101   100       0.7   5  31   2   54\n",
      "1  30101   200       0.7   9  26   2   47\n",
      "2  30101   300       0.5  12  15   2   52\n",
      "3  30101   400  0.599999   6  19   3   40\n",
      "4  30101   500       0.5   3  21   1   64\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO O3 NO2 SO2 PM10\n",
      "0  30101   100  0.799998  2  35   5   51\n",
      "1  30101   200  0.799998  2  33   5   45\n",
      "2  30101   300  0.499998  4  26   1   42\n",
      "3  30101   400  0.599998  3  25   0   37\n",
      "4  30101   500  0.599998  1  27   2   53\n",
      "     date  hour   CO NO2 SO2 O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100    1  28   4  6   65         NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.7  27   3  5   39         NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.2  28   2  6   10         NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.2  29   2  5   16         NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.4  27   3  5   24         NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100    1  18   3  40   26   NaN\n",
      "1  170101   200  0.9  21   4  34   21   NaN\n",
      "2  170101   300  0.9  19   3  35   18   NaN\n",
      "3  170101   400  0.9  17   3  35   16   NaN\n",
      "4  170101   500  0.9  17   3  34   16   NaN\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour   CO O3 NO2 SO2 PM10\n",
      "0  30101   100  1.5  5  47   6   89\n",
      "1  30101   200  1.5  5  44   2   49\n",
      "2  30101   300  1.3  5  36   1   44\n",
      "3  30101   400  1.3  4  33   2   42\n",
      "4  30101   500  1.4  4  32   4   57\n",
      "     date  hour   CO NO2 SO2  O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
      "0  100101   100    1  15   3  16   37         NaN         NaN         NaN   \n",
      "1  100101   200  1.1  19   3  11   31         NaN         NaN         NaN   \n",
      "2  100101   300  1.1  23   3   7   35         NaN         NaN         NaN   \n",
      "3  100101   400  0.7  16   3  13   37         NaN         NaN         NaN   \n",
      "4  100101   500  0.9  15   3  13   30         NaN         NaN         NaN   \n",
      "\n",
      "   ...  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
      "0  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "1  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "2  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "3  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "4  ...          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "     date  hour CO NO2 SO2 O3 PM10 PM2.5\n",
      "0  170101   100  -   -   -  -    -   NaN\n",
      "1  170101   200  -   -   -  -    -   NaN\n",
      "2  170101   300  -   -   -  -    -   NaN\n",
      "3  170101   400  -   -   -  -    -   NaN\n",
      "4  170101   500  -   -   -  -    -   NaN\n",
      "    date  hour    CO(ppm) PM10(มคก./ลบ.ม.)\n",
      "0  10101   100   0.599999               57\n",
      "1  10101   200        1.1               84\n",
      "2  10101   300          1               73\n",
      "3  10101   400  0.0999999               66\n",
      "4  10101   500        0.2               69\n",
      "    date  hour    CO(ppm) PM10(มคก./ลบ.ม.)\n",
      "0  80101   100        0.2               62\n",
      "1  80101   200  0.0999999               64\n",
      "2  80101   300          0               55\n",
      "3  80101   400          0               59\n",
      "4  80101   500          0               54\n",
      "     date  hour CO(ppm) PM10  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
      "0  150101   100     2.2    -         NaN         NaN         NaN         NaN\n",
      "1  150101   200     1.5    -         NaN         NaN         NaN         NaN\n",
      "2  150101   300     1.2    -         NaN         NaN         NaN         NaN\n",
      "3  150101   400     1.1    -         NaN         NaN         NaN         NaN\n",
      "4  150101   500     1.1    -         NaN         NaN         NaN         NaN\n",
      "     date  hour  CO  NO2 PM10 PM2.5\n",
      "0  170601   100 NaN  NaN  NaN   NaN\n",
      "1  170601   200 NaN  NaN  NaN   NaN\n",
      "2  170601   300 NaN  NaN  NaN   NaN\n",
      "3  170601   400 NaN  NaN  NaN   NaN\n",
      "4  170601   500 NaN  NaN  NaN   NaN\n",
      "     date  hour             CO            NO            O3           NO2  \\\n",
      "0  960101   100                                                            \n",
      "1  960101   200                                                            \n",
      "2  960101   300                                                            \n",
      "3  960101   400                                                            \n",
      "4  960101   500                                                            \n",
      "\n",
      "             SO2          PM10  \n",
      "0                               \n",
      "1                               \n",
      "2                               \n",
      "3                               \n",
      "4                               \n",
      "    date  hour             CO            O3           NO2            SO2 PM10\n",
      "0  30101   100            1.7             3            50              7   79\n",
      "1  30101   200            1.6             2            42              5   86\n",
      "2  30101   300                                                             82\n",
      "3  30101   400            1.1             4            32              4   54\n",
      "4  30101   500            1.9             3            37              7   70\n",
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.9  20   0  10   19   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.9  23   0   8   23   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.9  23   0   8   15   NaN         NaN         NaN  ...   \n",
      "3  100101   400    1  25   0   5   20   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.8  15   0  12   16   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 24  Unnamed: 25  Unnamed: 26  Unnamed: 27  Unnamed: 28  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "     date  hour   CO NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100  0.8  20   2  26   68    58\n",
      "1  170101   200  0.7  19   2  26   47    40\n",
      "2  170101   300  0.7  18   2  24   41    38\n",
      "3  170101   400  0.7  19   1  23   49    41\n",
      "4  170101   500  0.8  20   1  20   47    33\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour        CO O3 NO2 SO2 PM10\n",
      "0  30101   100       1.3  4  36   5   33\n",
      "1  30101   200       1.3  4  34   5   30\n",
      "2  30101   300       0.7  6  24   2   23\n",
      "3  30101   400  0.599999  5  20   2   18\n",
      "4  30101   500         1  3  23   2   23\n",
      "     date  hour   CO NO2 SO2 O3 PM10  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  1.3  32   4  3   35         NaN         NaN         NaN  ...   \n",
      "1  100101   200  1.5  33   7  3   30         NaN         NaN         NaN  ...   \n",
      "2  100101   300  1.3  32   7  3   22         NaN         NaN         NaN  ...   \n",
      "3  100101   400  1.3  30   7  4   15         NaN         NaN         NaN  ...   \n",
      "4  100101   500  1.3  30   5  4   18         NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 12  Unnamed: 13  Unnamed: 14  Unnamed: 15  Unnamed: 16  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date  hour  CO  NO2 PM10 PM2.5\n",
      "0  170601   100 NaN  NaN  NaN   NaN\n",
      "1  170601   200 NaN  NaN  NaN   NaN\n",
      "2  170601   300 NaN  NaN  NaN   NaN\n",
      "3  170601   400 NaN  NaN  NaN   NaN\n",
      "4  170601   500 NaN  NaN  NaN   NaN\n",
      "     date  hour             CO            O3           NO2            SO2  \\\n",
      "0  960101   100                                                             \n",
      "1  960101   200                                                             \n",
      "2  960101   300                                                             \n",
      "3  960101   400                                                             \n",
      "4  960101   500                                                             \n",
      "\n",
      "           PM10  \n",
      "0                \n",
      "1                \n",
      "2                \n",
      "3                \n",
      "4                \n",
      "    date  hour   CO O3 NO2 SO2 PM10\n",
      "0  30101   100  3.9  3  47  12   51\n",
      "1  30101   200  4.7  3  46  12   50\n",
      "2  30101   300  2.1  3  34   4   58\n",
      "3  30101   400  2.7  3  33   8   69\n",
      "4  30101   500  3.5  4  37  10   70\n",
      "    date  hour             CO   O3           NO2            SO2           PM10\n",
      "0  40101   100                 NaN                                            \n",
      "1  40101   200                 NaN                                            \n",
      "2  40101   300                 NaN                                            \n",
      "3  40101   400                 NaN                                            \n",
      "4  40101   500                 NaN                                            \n",
      "     date  hour    CO NO2 SO2  O3 PM10 PM2.5  Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.36  20   1  12   34   NaN         NaN         NaN  ...   \n",
      "1  100101   200  0.25  20   0  11   60   NaN         NaN         NaN  ...   \n",
      "2  100101   300  0.22  21   0   9   48   NaN         NaN         NaN  ...   \n",
      "3  100101   400  0.28  20   1   9   14   NaN         NaN         NaN  ...   \n",
      "4  100101   500  0.24  17   0  12   26   NaN         NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "     date  hour   CO NO2  O3 PM10 PM2.5\n",
      "0  170101   100    -   -   -   58    33\n",
      "1  170101   200  0.9  18  23   46    32\n",
      "2  170101   300  0.9  18  22   41    28\n",
      "3  170101   400  0.9  18  21   38    25\n",
      "4  170101   500  0.9  17  20   37    24\n",
      "    date  hour             CO            O3           NO2            SO2  \\\n",
      "0  50101   100                                                             \n",
      "1  50101   200                                                             \n",
      "2  50101   300                                                             \n",
      "3  50101   400                                                             \n",
      "4  50101   500                                                             \n",
      "\n",
      "            PM10  \n",
      "0                 \n",
      "1                 \n",
      "2                 \n",
      "3                 \n",
      "4                 \n",
      "     date  hour   CO NO2 SO2 O3 PM10 PM2.5 Unnamed: 8  Unnamed: 9  ...  \\\n",
      "0  100101   100  0.9  15   4  3   37   NaN        NaN         NaN  ...   \n",
      "1  100101   200  0.9  14   4  3   37   NaN        NaN         NaN  ...   \n",
      "2  100101   300  0.9  14   4  3   46   NaN        NaN         NaN  ...   \n",
      "3  100101   400  0.9  14   5  4   50   NaN        NaN         NaN  ...   \n",
      "4  100101   500  0.8  14   4  3   52   NaN        NaN         NaN  ...   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "     date  hour NO2 SO2  O3 PM10 PM2.5\n",
      "0  170101   100   7   2  31   66    52\n",
      "1  170101   200  11   2  26   44    36\n",
      "2  170101   300   9   2  27   38    37\n",
      "3  170101   400   2   1  32   38    36\n",
      "4  170101   500   1   1  33   37    34\n",
      "['02t', '03t', '05t', '11t', '12t', '50t', '52t', '53t', '59t', '61t']\n",
      "['10t', '54t']\n"
     ]
    }
   ],
   "source": [
    "# process bangkok data\n",
    "station_ids = ['02t',\n",
    " '03t',\n",
    " '05t',\n",
    " '10t',\n",
    " '11t',\n",
    " '12t',\n",
    " '50t',\n",
    " '52t',\n",
    " '53t',\n",
    " '54t',\n",
    " '59t',\n",
    " '61t']\n",
    "\n",
    "good_stations = []\n",
    "bad_stations = []\n",
    "for ids in station_ids:\n",
    "    path = Path(aqm_folder)\n",
    "    files = [*path.rglob(f'({ids})*.xlsx')]\n",
    "    try:\n",
    "        df = read_his_xl(files[0])\n",
    "    except:\n",
    "        bad_stations.append(ids)\n",
    "    else:\n",
    "        good_stations.append(ids)\n",
    "        df.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/aqm_hourly2/process/'+ids+'.csv')\n",
    "        \n",
    "print(good_stations)\n",
    "print(bad_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Power Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://th.wikipedia.org/wiki/%E0%B8%A3%E0%B8%B2%E0%B8%A2%E0%B8%8A%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B9%82%E0%B8%A3%E0%B8%87%E0%B9%84%E0%B8%9F%E0%B8%9F%E0%B9%89%E0%B8%B2%E0%B9%83%E0%B8%99%E0%B9%84%E0%B8%97%E0%B8%A2'\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_power_stations_in_Thailand'\n",
    "table_list = pd.read_html(url)\n",
    "len(table_list)\n",
    "p_folder = '../data/power_plants/'\n",
    "for i, table in enumerate(table_list):\n",
    "    table.to_csv(p_folder + f'table_eng{i}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/*/')\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bkk 13\n",
      "chiang-mai 36\n",
      "chiang-rai 25\n",
      "kungming 24\n",
      "luang-prabang 24\n",
      "sikhottabong 39\n",
      "tada_u 24\n",
      "tak 26\n",
      "yangong 29\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    city_name = Path(folder).name\n",
    "    parent_folder = Path(folder).parent\n",
    "    w_files = glob(folder + '/*.csv')\n",
    "    print(city_name, len(w_files))\n",
    "    filename = str(Path(folders[0]).parent) + '/' + city_name + '.csv'\n",
    "    \n",
    "    # concatenate all files \n",
    "    df_all = pd.DataFrame()\n",
    "    for file in w_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    \n",
    "    # drop missing value \n",
    "    df_all['datetime'] = pd.to_datetime(df_all['date'])\n",
    "    df_all.drop('date',axis=1, inplace=True)\n",
    "    df_all = df_all.sort_values('datetime')\n",
    "    df_all = df_all.drop_duplicates('datetime', ignore_index=True)\n",
    "    \n",
    "    # save file\n",
    "    df_all.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing date for chiang-mai data \n",
    "df_all = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv')\n",
    "df_all['datetime'] = pd.to_datetime(df_all['datetime'] )\n",
    "# find exisiting date \n",
    "ex_date = df_all['datetime'].dt.strftime('%Y-%m-%d').unique()\n",
    "ex_date = set(ex_date)\n",
    "# calculate the datelist \n",
    "start_date = datetime(2000, 10, 1)\n",
    "stop_date = datetime.now()\n",
    "date_range = pd.date_range(start_date, stop_date).strftime('%Y-%m-%d')\n",
    "missing_date = list(set(date_range).difference(ex_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'Mueang Chiang Mai', 'province': 'Chiang Mai', 'country': 'Thailand', 'station_name': 'Chiang Mai International Airport Station', 'specific_url': 'th/mueang-chiang-mai/', 'latitude': '18.8 °N', 'longitude': '98.97 °E'}\n"
     ]
    }
   ],
   "source": [
    "with open('../data/weather_cities/weather_station_info.json','r') as f:\n",
    "    station_dict_list = json.load(f)\n",
    "   \n",
    "i = 0 \n",
    "city_json = station_dict_list[i]\n",
    "print(city_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/mueang-chiang-mai_weather.csv 2000-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\src\\data\\dl_weather.py:20: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 20 of the file ..\\src\\data\\dl_weather.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(innerhtml)\n"
     ]
    }
   ],
   "source": [
    " bad_date_df = scrape_weather(city_json, date_range=missing_date, data_folder='C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333126, 11)\n"
     ]
    }
   ],
   "source": [
    "# weather data \n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/chiang-mai.csv'\n",
    "wea = pd.read_csv(filename)\n",
    "wea['datetime']  = pd.to_datetime(wea['datetime'])\n",
    "# roud datetiem to whole 30 mins \n",
    "wea['datetime'] = wea['datetime'].dt.round('30T')\n",
    "\n",
    "dates = wea['datetime'].dropna().dt.date.unique()\n",
    "\n",
    "# fill in the missing value\n",
    "new_datetime = pd.date_range(start=dates[0], end=dates[-1], freq='30T') \n",
    "new_weather = pd.DataFrame(new_datetime, columns=['datetime'])\n",
    "new_weather = new_weather.merge(wea, on='datetime',how='left')\n",
    "print(new_weather.shape)\n",
    "\n",
    "# remove strange T reading\n",
    "lowest_t = 5 \n",
    "idx = new_weather[new_weather['Temperature(C)']< lowest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "highest_t = 60\n",
    "idx = new_weather[new_weather['Temperature(C)']> highest_t].index\n",
    "new_weather.loc[idx,['Temperature(C)','Dew Point(C)','Humidity(%)']] = np.nan\n",
    "\n",
    "new_weather = new_weather.fillna(method='ffill',limit=12)\n",
    "new_weather = new_weather.fillna(method='bfill',limit=12)\n",
    "new_weather = new_weather.set_index('datetime')\n",
    "new_weather = new_weather.dropna(how='all').reset_index()\n",
    "new_weather.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Assemble from raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# weather folder\n",
    "w_folder = '../data/weather_cities/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Mueang Chiang Rai', 'Mueang Tak','Bangkok','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "36\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "25\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Mueang_Tak.csv\n",
      "26\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Bangkok.csv\n",
      "13\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime', 'Temperature(F)', 'Dew Point(F)',\n",
      "       'Precip Accum(in)'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Yangon.csv\n",
      "28\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Tada-U.csv\n",
      "23\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Sikhottabong.csv\n",
      "39\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Luang_Prabang_District.csv\n",
      "24\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n",
      "../data/weather_cities/Kunming.csv\n",
      "24\n",
      "Index(['Time', 'Temperature(C)', 'Dew Point(C)', 'Humidity(%)', 'Wind',\n",
      "       'Wind Speed(mph)', 'Wind Gust(mph)', 'Pressure(in)', 'Precip.(in)',\n",
      "       'Condition', 'datetime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# concatenate raw data files\n",
    "for city_json in weather_station_info: \n",
    "    # read existing file \n",
    "    city_name = ('_').join(city_json['city_name'].split(' '))\n",
    "    current_filename = w_folder + city_name + '.csv'\n",
    "    print(current_filename)\n",
    "    \n",
    "    # locate file in the city folder\n",
    "    files = glob(w_folder + city_name + '/*.csv')\n",
    "    print(len(files))\n",
    "    \n",
    "    weather_all = pd.DataFrame()\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if 'date'== df.columns[-1]:\n",
    "                df.columns = df.columns.str.replace('date','datetime')\n",
    "            weather_all = pd.concat([weather_all, df],ignore_index=True)\n",
    "        \n",
    "    print(weather_all.columns)\n",
    "    weather_all.to_csv(current_filename, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities\\Bangkok.csv\n",
      "../data/weather_cities\\Kunming.csv\n",
      "../data/weather_cities\\Luang_Prabang_District.csv\n",
      "../data/weather_cities\\Mueang_Chiang_Mai.csv\n",
      "../data/weather_cities\\Mueang_Chiang_Rai.csv\n",
      "../data/weather_cities\\Mueang_Tak.csv\n",
      "../data/weather_cities\\Sikhottabong.csv\n",
      "../data/weather_cities\\Tada-U.csv\n",
      "../data/weather_cities\\Yangon.csv\n"
     ]
    }
   ],
   "source": [
    "# fix the unit of windspeed \n",
    "files = glob(w_folder + '/*.csv')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df[['Wind Speed(mph)', 'Wind Gust(mph)']] = df[['Wind Speed(mph)', 'Wind Gust(mph)']]*1.60934\n",
    "    df[['Wind Speed(mph)', 'Wind Gust(mph)']] = df[['Wind Speed(mph)', 'Wind Gust(mph)']].round(0)\n",
    "    df.columns = df.columns.str.replace('mph', 'kmph')\n",
    "    df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate datetime \n",
    "files = glob(w_folder + '/*.csv')\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df = df.drop_duplicates('datetime')\n",
    "    df.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill the missing value in raw Weather Data \n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = fill_missing_weather(df,limit=12)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update weather all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/weather_cities/Mueang_Chiang_Mai.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime.now()\n",
    "city_json = weather_station_info[i]\n",
    "# read existing file \n",
    "city_name = ('_').join(city_json['city_name'].split(' '))\n",
    "current_filename = w_folder + city_name + '.csv'\n",
    "print(current_filename)\n",
    "\n",
    "# obtain a list of existed dates\n",
    "wea = pd.read_csv(current_file)\n",
    "wea['datetime'] = pd.to_datetime(wea['datetime'])\n",
    "# find exisiting date \n",
    "ex_date = wea['datetime'].dt.strftime('%Y-%m-%d').unique()\n",
    "ex_date = set(ex_date)\n",
    "\n",
    "# calculate the missing dates \n",
    "date_range = pd.date_range(start_date, end_date).strftime('%Y-%m-%d')\n",
    "missing_date = list(set(date_range).difference(ex_date))\n",
    "missing_date.sort()\n",
    "len(missing_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract station information\n",
    "city_names = ['Mueang Chiang Mai', 'Mueang Chiang Rai', 'Mueang Tak','Bangkok','Yangon', 'Tada-U', 'Sikhottabong', 'Luang Prabang District','Kunming']\n",
    "weather_station_info = find_weather_stations(city_names, weather_json_file=w_folder+'weather_station_info.json')\n",
    "len(weather_station_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                               | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Chiang_Mai.csv\n",
      "missing date 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:28, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:02, 30.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:35, 30.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:04, 30.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:33, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:02, 29.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:30, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:00, 29.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:29, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [04:59, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:32, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:05, 31.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:35, 30.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:04, 30.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:34, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:03, 29.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:37, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:07, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:39, 31.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:11, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:40, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:08, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:42, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:14, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:42, 30.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:10, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:42, 30.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:10, 29.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:42, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:11, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:40, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:09, 29.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:40, 29.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:09, 29.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:39, 29.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:09, 29.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:41, 30.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:14, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:47, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:16, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:45, 30.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:19, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:50, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:20, 30.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:49, 30.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:18, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:51, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:19, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:48, 29.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:18, 29.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:47, 29.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:17, 29.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:52, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:21, 30.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:49, 29.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:20, 30.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:49, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:20, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:51, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:20, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [30:51, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:19, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:50, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:23, 30.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:51, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:21, 30.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:54, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:22, 30.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [34:50, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:19, 29.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [35:47, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:18, 29.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [36:47, 29.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:19, 30.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [37:50, 30.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:18, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [38:46, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:15, 29.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [39:43, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:11, 28.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [40:40, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:10, 28.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [41:38, 28.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:06, 28.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [42:35, 28.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:05, 29.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [43:34, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:03, 28.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [44:31, 28.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:03, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [45:34, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:12, 32.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [46:44, 32.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:16, 32.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [47:50, 32.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [48:38, 37.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:11, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [49:48, 36.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:20, 35.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [50:53, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [51:24, 33.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [51:57, 33.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [52:35, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [53:10, 34.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [53:43, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [54:15, 33.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [54:47, 33.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [55:20, 32.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [55:51, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [56:19, 31.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [56:53, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [57:22, 31.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [57:54, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [58:25, 31.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [58:57, 31.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [59:27, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [59:58, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:00:28, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:00:57, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:01:27, 30.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:01:56, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:02:25, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:02:55, 29.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:03:25, 29.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:03:56, 30.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:04:26, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:04:55, 29.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:05:24, 30.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|██████████▊                                                                                      | 1/9 [1:05:46<8:46:09, 3946.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Chiang_Rai.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:34, 34.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:07, 33.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:36, 32.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:04, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:37, 31.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:10, 32.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:39, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:07, 30.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:37, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:05, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:38, 30.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:06, 29.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:34, 29.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:02, 28.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:31, 28.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:00, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:29, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [08:58, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:26, 28.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [09:54, 28.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:22, 28.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [10:53, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:22, 29.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [11:51, 29.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:20, 29.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [12:50, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:24, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [13:52, 29.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:20, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [14:49, 29.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:19, 29.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [15:50, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:23, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [16:52, 30.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:21, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [17:49, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:18, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [18:49, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:17, 29.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [19:48, 29.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:21, 30.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [20:52, 30.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:21, 30.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [21:50, 29.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:19, 29.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [22:49, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:18, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [23:47, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:18, 29.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [24:47, 29.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:16, 29.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [25:46, 29.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:15, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [26:44, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:13, 29.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [27:42, 29.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:10, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [28:40, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:09, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [29:38, 29.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [30:08, 29.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [30:37, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:06, 29.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [31:35, 29.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:04, 29.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [32:32, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:01, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [33:29, 28.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [33:58, 28.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [34:27, 28.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [34:56, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [35:24, 28.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [35:54, 28.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [36:23, 29.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [36:52, 29.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [37:20, 28.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [37:49, 28.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [38:18, 28.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [38:46, 28.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [39:15, 28.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [39:44, 28.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [40:12, 28.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [40:42, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [41:11, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [41:39, 28.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [42:08, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [42:40, 29.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [43:09, 29.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [43:38, 29.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [44:06, 29.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [44:35, 28.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [45:03, 28.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [45:32, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [46:01, 28.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [46:30, 28.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [46:59, 28.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [47:27, 28.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [47:57, 28.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [48:27, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [48:57, 29.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [49:26, 29.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [49:56, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [50:24, 29.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [50:54, 29.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [51:23, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [51:51, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [52:20, 28.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [52:49, 28.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [53:33, 33.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [54:02, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [54:31, 31.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [55:00, 30.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [55:30, 30.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [55:59, 30.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [56:29, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [56:58, 29.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [57:27, 29.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [57:56, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [58:25, 29.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [58:55, 29.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [59:24, 29.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [59:53, 29.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:00:23, 29.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|█████████████████████▌                                                                           | 2/9 [2:06:30<7:29:50, 3855.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Mueang_Tak.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:40, 40.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:13, 38.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:44, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:16, 35.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:47, 33.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:17, 32.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:53, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:23, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:01, 34.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:36, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:07, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:37, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:09, 32.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:40, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:11, 31.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:42, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:13, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:43, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:15, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:46, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [11:27, 33.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:59, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:31, 33.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:05, 33.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:37, 32.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:10, 32.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:40, 32.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:15, 32.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:45, 32.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [16:20, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:52, 32.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [17:23, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:54, 31.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [18:26, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [18:59, 32.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [19:31, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [20:05, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [20:37, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [21:10, 32.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [21:43, 32.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [22:17, 33.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [22:50, 32.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:21, 32.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:55, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [24:26, 32.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [25:02, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [25:33, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [26:03, 31.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [26:37, 32.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [27:07, 31.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [27:39, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [28:13, 32.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [28:45, 32.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:17, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [29:49, 32.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:21, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [30:52, 31.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [31:23, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [31:54, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [32:24, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [32:54, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [33:27, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [33:59, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [34:32, 31.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [35:08, 33.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [35:42, 33.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [36:15, 33.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [36:48, 33.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [37:19, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [37:50, 32.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [38:20, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [38:51, 31.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [39:22, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [39:53, 31.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [40:24, 31.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [40:57, 31.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [41:28, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [42:01, 31.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [42:31, 31.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [43:07, 32.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [43:38, 32.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [44:10, 32.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [44:42, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [45:16, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [45:47, 32.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [46:20, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [46:50, 31.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [47:22, 31.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [47:52, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [48:23, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [48:54, 31.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [49:26, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [49:59, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [50:31, 32.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [51:06, 32.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [51:37, 32.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [52:09, 32.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [52:40, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [53:10, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [53:42, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [54:13, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [54:44, 31.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [55:17, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [55:48, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [56:19, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [56:49, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [57:20, 31.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [57:53, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [58:25, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [58:57, 31.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [59:27, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:00:05, 33.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:00:36, 32.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:01:07, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:01:39, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:02:13, 32.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:08:41, 139.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:09:20, 109.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:09:51, 85.79s/it] \u001b[A\u001b[A\n",
      "\n",
      "120it [1:10:23, 69.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:10:59, 59.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:11:33, 51.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:12:08, 35.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████████████████████████▎                                                                | 3/9 [3:18:58<6:40:19, 4003.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Bangkok.csv\n",
      "missing date 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:33, 33.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:05, 33.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:34, 31.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:06, 31.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:39, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:07, 30.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:35, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:03, 29.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:32, 29.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:05, 30.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:38, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:10, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:38, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:12, 31.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:47, 32.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:15, 31.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:43, 30.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:15, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:48, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:17, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:48, 30.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:20, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:52, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:24, 31.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:51, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:23, 30.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:55, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:27, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:55, 30.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:27, 30.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:55, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:27, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:54, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:22, 29.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:54, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:26, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:58, 31.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:31, 31.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [20:02, 31.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:35, 31.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [21:02, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:36, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [22:08, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:36, 30.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [23:04, 29.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:31, 29.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [24:03, 29.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:32, 29.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [25:05, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:37, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [26:04, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:36, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [27:09, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:42, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [28:10, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:38, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [29:07, 29.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:37, 29.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [30:09, 30.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:41, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [31:09, 29.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:41, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [32:10, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:38, 29.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [33:06, 29.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:34, 28.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [34:06, 29.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:39, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [35:07, 29.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:39, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [36:12, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:45, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [37:16, 31.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:44, 30.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [38:12, 29.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:45, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [39:13, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:46, 30.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [40:14, 30.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:42, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [41:10, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:42, 29.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [42:10, 29.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:38, 28.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [43:10, 30.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:44, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [44:16, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:48, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [45:15, 30.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:44, 29.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [46:16, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:48, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [47:21, 31.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:52, 31.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [48:39, 36.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [49:08, 33.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:39, 33.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [50:11, 32.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:39, 31.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [51:07, 30.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [51:35, 29.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [52:08, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [52:41, 31.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [53:08, 30.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [53:42, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [54:15, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [54:43, 30.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [55:17, 31.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [55:49, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [56:17, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [56:45, 29.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [57:13, 29.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [57:42, 29.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [58:11, 29.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [58:47, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [59:21, 32.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:00:14, 38.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:01:46, 54.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:02:22, 48.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:02:52, 43.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:03:21, 38.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:03:56, 37.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:04:30, 36.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:04:59, 34.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:05:27, 32.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:05:55, 31.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:06:25, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:07:07, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|███████████████████████████████████████████                                                      | 4/9 [4:26:36<5:34:58, 4019.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Yangon.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:35, 35.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:13, 36.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:48, 36.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:23, 35.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:58, 35.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:33, 35.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:10, 35.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:42, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:16, 34.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:49, 34.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:21, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:52, 32.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:26, 33.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:04, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:38, 34.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:12, 34.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:49, 35.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:23, 34.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:57, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [11:27, 33.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [12:01, 33.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [12:36, 33.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [13:05, 32.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:42, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [14:17, 34.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:52, 34.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [15:23, 33.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:57, 33.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [16:29, 33.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [17:04, 33.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [17:41, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [18:16, 34.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [18:50, 34.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [20:25, 52.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [20:59, 47.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [21:33, 43.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [22:05, 39.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [22:40, 38.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [23:14, 36.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [23:50, 36.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [24:26, 36.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [25:03, 36.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [26:38, 54.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [27:13, 48.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [27:47, 44.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [28:22, 41.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [28:57, 39.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [29:30, 37.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [30:09, 37.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [30:45, 37.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [32:20, 54.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [32:54, 48.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [33:32, 45.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [34:10, 43.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [34:45, 40.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [36:19, 56.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [36:54, 50.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [37:28, 45.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [38:02, 42.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [38:38, 40.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [39:12, 38.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [39:42, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [40:17, 35.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [40:48, 34.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [41:22, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [41:52, 32.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [42:25, 32.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [43:00, 33.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [43:31, 32.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [44:05, 33.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [44:39, 33.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [45:15, 34.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [45:49, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [46:23, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [46:55, 33.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [47:26, 32.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [48:02, 33.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [48:41, 35.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [49:15, 34.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [49:45, 33.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [50:19, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [50:56, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [51:32, 34.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [52:07, 35.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [52:44, 35.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [53:15, 34.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [54:03, 38.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [54:39, 37.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [55:17, 37.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [55:51, 36.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [56:26, 36.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [56:59, 35.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [57:33, 34.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [58:06, 34.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [58:40, 34.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [59:13, 33.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [59:43, 32.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [1:00:15, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [1:00:51, 33.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [1:01:25, 33.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [1:01:55, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [1:02:28, 32.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [1:03:01, 32.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [1:03:34, 32.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [1:04:05, 32.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [1:04:39, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:05:09, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:05:40, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:06:11, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:06:44, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:07:15, 31.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:07:46, 31.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:08:20, 32.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:08:51, 32.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:09:23, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:10:03, 34.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:10:33, 33.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:11:07, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:11:38, 32.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:12:09, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:12:41, 31.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:13:17, 33.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:13:47, 35.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████████████████████████████████████▉                                           | 5/9 [5:40:52<4:36:42, 4150.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Tada-U.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:41, 41.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:11, 38.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:41, 35.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:13, 34.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:43, 33.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:11, 31.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:41, 31.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:10, 30.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:39, 30.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:08, 29.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:46, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:15, 31.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:46, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:15, 30.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:45, 30.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:14, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:44, 29.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:17, 30.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:50, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:19, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:54, 32.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:29, 32.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:03, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:37, 33.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:10, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:39, 32.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:11, 32.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:41, 31.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:10, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:43, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:12, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:45, 31.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:18, 31.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:47, 31.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [18:17, 30.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:45, 30.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [19:18, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:48, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [20:18, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:52, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [21:21, 30.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:53, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:25, 49.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:55, 43.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [25:25, 57.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [25:55, 49.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [26:23, 42.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [26:57, 40.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [27:27, 37.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [27:56, 34.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [28:25, 32.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [28:57, 32.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [29:26, 31.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:54, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [30:23, 30.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:53, 29.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [31:29, 31.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [32:01, 31.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [32:30, 31.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [34:01, 48.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [35:32, 61.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [36:07, 53.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [36:36, 46.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [37:09, 42.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [37:42, 39.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [38:12, 36.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [38:46, 35.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [39:14, 33.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [39:44, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [40:16, 32.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [40:55, 34.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [41:23, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [41:56, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [42:25, 31.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [42:54, 30.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [43:27, 31.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [43:57, 31.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [44:26, 30.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [44:55, 30.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [45:25, 29.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [45:58, 30.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [46:31, 31.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [46:59, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [47:32, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [48:04, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [48:37, 31.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [49:06, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [49:39, 31.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [50:12, 31.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [50:49, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [51:19, 32.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [51:53, 32.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [52:21, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [52:55, 32.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [53:23, 31.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [53:53, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [54:26, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [54:55, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [56:19, 46.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [56:48, 41.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [57:22, 39.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [57:51, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [58:20, 34.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [58:52, 33.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [59:21, 32.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [59:54, 32.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:00:25, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:00:54, 31.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:01:27, 31.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:01:58, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:02:27, 30.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:02:56, 30.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:03:28, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:03:58, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:04:30, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:05:04, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:05:37, 32.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:06:05, 31.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:06:34, 30.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:07:04, 30.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:07:38, 31.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:08:10, 31.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:08:39, 33.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|████████████████████████████████████████████████████████████████▋                                | 6/9 [6:50:02<3:27:31, 4150.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Sikhottabong.csv\n",
      "missing date 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:55, 55.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:33, 50.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [02:05, 44.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:44, 43.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [03:22, 41.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:55, 38.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:26, 36.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:56, 34.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:26, 33.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:56, 32.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:32, 33.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [07:03, 32.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:36, 32.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:09, 32.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [08:40, 32.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:10, 31.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [09:39, 30.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:10, 30.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [10:39, 30.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [11:09, 30.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [11:40, 30.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [12:12, 30.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [12:42, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [13:12, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [13:45, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [14:15, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [14:44, 30.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [15:17, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [15:50, 31.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [16:19, 30.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [16:52, 31.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [17:26, 32.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [17:59, 32.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [18:32, 32.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [19:02, 31.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [19:32, 31.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [20:01, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [20:37, 32.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [21:11, 32.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [21:41, 31.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [22:11, 31.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [22:40, 30.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [23:14, 31.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [23:43, 30.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [24:17, 31.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [24:46, 30.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [25:15, 30.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [25:49, 31.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [26:19, 30.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [26:48, 30.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [27:22, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [27:57, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [28:36, 34.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [29:09, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [29:43, 33.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [30:15, 33.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [30:48, 33.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [31:22, 33.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [31:53, 32.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [32:26, 32.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [32:57, 32.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [33:27, 31.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [34:00, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [34:30, 31.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [35:01, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [35:33, 31.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [36:03, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [36:44, 33.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [37:14, 32.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [37:44, 31.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [39:20, 51.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [39:49, 44.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [40:22, 41.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [40:52, 37.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [41:21, 35.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [41:54, 34.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [42:24, 33.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [42:55, 32.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [43:33, 34.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [44:06, 33.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [44:41, 34.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [45:14, 33.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [45:47, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [46:17, 32.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [46:46, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [47:19, 31.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [47:48, 31.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [48:18, 30.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [48:47, 30.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [49:16, 30.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [49:50, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [50:19, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [50:49, 30.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [51:19, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [51:52, 31.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [52:25, 31.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [52:58, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [53:28, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [53:59, 31.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [54:28, 30.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [54:58, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [55:33, 31.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [56:06, 32.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [56:42, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [57:12, 32.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [57:44, 32.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [58:14, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [58:44, 30.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [59:14, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [59:48, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:00:22, 32.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:00:55, 32.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:01:30, 33.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:02:07, 34.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:03:40, 52.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:04:15, 47.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:04:49, 43.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:05:20, 39.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:05:56, 38.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:06:32, 37.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:07:07, 36.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:07:37, 34.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:08:16, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████████████████▍                     | 7/9 [7:58:49<2:18:06, 4143.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Luang_Prabang_District.csv\n",
      "missing date 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:49, 49.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:29, 46.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [02:00, 41.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:37, 40.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [03:09, 37.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:46, 37.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [04:22, 37.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:59, 36.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [05:35, 36.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [06:10, 36.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [06:45, 35.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [07:17, 34.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [07:51, 34.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [08:25, 34.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [09:01, 34.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [09:36, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [10:07, 33.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [10:45, 34.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [11:24, 36.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [12:02, 36.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [12:42, 37.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [13:17, 37.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [13:51, 36.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [15:24, 53.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [16:01, 48.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [16:35, 43.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [17:08, 40.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [17:55, 42.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [18:29, 39.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [19:04, 38.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [19:41, 38.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [20:18, 37.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [20:52, 36.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [21:28, 36.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [22:02, 35.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [22:37, 35.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [23:13, 35.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [23:51, 36.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [24:25, 35.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [24:56, 34.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [25:31, 34.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [26:02, 33.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [26:32, 32.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [27:08, 33.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [27:47, 35.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [28:23, 35.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [28:58, 35.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [29:31, 34.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [30:06, 34.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [30:37, 33.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [31:12, 34.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [31:47, 34.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [32:22, 34.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [33:00, 35.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [33:35, 35.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [34:05, 33.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [34:41, 34.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [35:16, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [35:47, 33.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [36:22, 33.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [36:54, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [37:24, 32.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [38:00, 33.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [38:35, 34.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [39:09, 34.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [39:44, 34.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [40:20, 34.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [41:06, 38.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [41:43, 37.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [42:19, 37.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [43:55, 54.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [44:29, 48.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [45:04, 44.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [45:40, 42.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [46:16, 40.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [46:51, 38.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [47:26, 37.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [47:57, 35.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [48:34, 35.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [49:09, 35.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [49:45, 35.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [50:20, 35.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [50:53, 34.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [51:27, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [52:02, 34.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [52:35, 34.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [53:08, 33.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [53:45, 34.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [54:18, 34.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [54:52, 34.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [55:26, 34.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [56:00, 34.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [56:33, 33.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [57:04, 32.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [57:42, 34.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [58:16, 34.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [58:48, 33.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [59:23, 34.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [59:56, 33.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [1:00:32, 34.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [1:01:08, 34.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [1:01:42, 34.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [1:02:17, 34.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [1:02:54, 35.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [1:03:25, 33.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [1:04:00, 34.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [1:04:30, 33.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [1:05:01, 32.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [1:05:37, 33.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [1:06:11, 33.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [1:06:49, 34.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [1:07:20, 33.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [1:07:59, 35.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [1:08:33, 34.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [1:09:07, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [1:09:41, 34.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [1:10:16, 34.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [1:10:47, 33.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [1:11:23, 34.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:11:54, 33.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:12:29, 33.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:13:03, 33.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:13:38, 34.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:14:12, 34.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:14:46, 34.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:15:22, 34.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:15:56, 34.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:16:31, 34.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "129it [1:17:06, 35.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████▏          | 8/9 [9:16:27<1:11:37, 4297.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateing file: ../data/weather_cities/Kunming.csv\n",
      "missing date 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:30, 30.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:03, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:30, 30.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:05, 31.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:37, 31.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [03:05, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:34, 30.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [04:06, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [04:38, 30.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [05:10, 31.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [05:42, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [06:17, 32.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [06:46, 31.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [07:17, 31.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [07:49, 31.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [08:21, 31.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [08:52, 31.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [09:25, 31.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [09:57, 32.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [10:26, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [10:57, 31.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [11:25, 30.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [11:57, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [12:25, 29.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [12:53, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [13:22, 29.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [13:49, 28.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [14:17, 28.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [14:48, 29.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [15:17, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [15:44, 28.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [16:12, 28.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [16:41, 28.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [17:08, 28.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [17:40, 29.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [18:11, 29.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [18:43, 30.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [19:15, 30.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [19:43, 30.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [20:15, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [20:43, 29.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [21:14, 30.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [21:46, 30.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [22:17, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [22:50, 31.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [23:18, 30.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [23:48, 30.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [24:19, 30.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [24:47, 29.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [25:19, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [25:47, 29.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [26:20, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [26:52, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [27:23, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [27:55, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [28:26, 31.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [28:57, 31.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [29:29, 31.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [29:57, 30.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [30:29, 30.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "61it [31:00, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "62it [31:28, 30.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "63it [31:56, 29.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "64it [32:24, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "65it [32:53, 29.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "66it [33:22, 29.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "67it [33:54, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "68it [34:26, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "69it [34:54, 29.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "70it [35:26, 30.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "71it [35:58, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "72it [36:31, 31.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "73it [37:03, 31.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [37:33, 31.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "75it [38:04, 31.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "76it [38:33, 30.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "77it [39:01, 29.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "78it [39:33, 30.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "79it [40:02, 29.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "80it [40:35, 30.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "81it [41:09, 31.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "82it [41:41, 31.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "83it [42:08, 30.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "84it [42:40, 30.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "85it [43:09, 30.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "86it [43:37, 29.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "87it [44:05, 29.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "88it [44:32, 28.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "89it [45:01, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "90it [45:29, 28.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "91it [46:01, 29.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "92it [46:28, 28.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "93it [47:00, 29.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "94it [47:31, 30.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "95it [48:03, 30.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "96it [48:31, 29.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "97it [49:02, 30.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "98it [49:34, 30.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "99it [50:02, 29.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "100it [50:30, 29.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "101it [50:57, 28.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "102it [51:25, 28.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [51:57, 29.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "104it [52:24, 28.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "105it [52:53, 28.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "106it [53:24, 29.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "107it [53:51, 28.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [54:22, 29.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [54:50, 28.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [55:18, 28.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [55:46, 28.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [56:17, 29.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [56:49, 29.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [57:18, 29.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [57:49, 30.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [58:21, 30.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [58:50, 30.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [59:25, 31.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [59:53, 30.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [1:00:26, 31.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [1:01:00, 32.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [1:01:28, 30.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [1:02:01, 31.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [1:02:30, 30.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [1:02:59, 30.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [1:03:27, 29.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [1:03:58, 30.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [1:04:31, 30.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "129it [1:05:04, 30.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [10:21:56<00:00, 4146.29s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for city_json in tqdm(weather_station_info):\n",
    "    \n",
    "    start_date = datetime(2020,1,1)\n",
    "    end_date = datetime.now()\n",
    "    update_weather(city_json, data_folder=w_folder, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holiday In Thailand\n",
    "\n",
    "https://www.timeanddate.com/holidays/thailand/2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2000,2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape holiday from all websites\n",
    "th_holiday = pd.DataFrame()\n",
    "for year in years:\n",
    "    url = f'https://www.timeanddate.com/holidays/thailand/{year}'\n",
    "    df = pd.read_html(url)[0]\n",
    "    df['year'] = year\n",
    "    th_holiday = pd.concat([th_holiday,df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday.columns = ['Date', 'day_of_week','name','type','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday = th_holiday[~th_holiday['Date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday['date'] = th_holiday['Date'] + ', ' + th_holiday['year'].astype(str)\n",
    "th_holiday['date'] = pd.to_datetime(th_holiday['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_holiday.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/th_holiday.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotspots Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stationID': '36t', 'nameTH': 'โรงเรียนยุพราชวิทยาลัย ', 'nameEN': 'Yupparaj Wittayalai School', 'areaTH': 'ต.ศรีภูมิ อ.เมือง, เชียงใหม่', 'areaEN': 'Si Phum, Meuang, Chiang Mai', 'stationType': 'GROUND', 'lat': '18.7909205', 'long': '98.9881062', 'LastUpdate': {'date': '2020-03-27', 'time': '03:00', 'PM25': {'value': '87', 'unit': 'µg/m³'}, 'PM10': {'value': '110', 'unit': 'µg/m³'}, 'O3': {'value': 'N/A', 'unit': 'ppb'}, 'CO': {'value': '1.09', 'unit': 'ppm'}, 'NO2': {'value': '-', 'unit': 'ppb'}, 'SO2': {'value': '2', 'unit': 'ppb'}, 'AQI': {'Level': '4', 'aqi': '192'}}}\n"
     ]
    }
   ],
   "source": [
    "# load stations information for Chiangmai\n",
    "station_info_file = aqm_folder + 'stations_locations.json'\n",
    "with open(station_info_file, 'r',encoding=\"utf8\") as f:\n",
    "    station_info = json.load(f)\n",
    "station_info = station_info['stations']\n",
    "\n",
    "print(station_info[124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117.0 11019.0\n"
     ]
    }
   ],
   "source": [
    "# obtain the lat and long in km\n",
    "lat_km = (merc_y(station_info[124]['lat'])/1E3 ).round()\n",
    "long_km = (merc_x(station_info[124]['long'])/1E3).round()\n",
    "print(lat_km,  long_km )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file map folder \n",
    "m_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6/*.csv')\n",
    "v_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/V1/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [13:35<00:00, 38.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "\n",
    "\n",
    "file_all = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(m_files):\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "     \n",
    "    file_all = pd.concat([file_all,f],ignore_index=True)\n",
    "        \n",
    "        \n",
    "file_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3242: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop (3901918, 18)\n",
      "after drop (3829241, 18)\n"
     ]
    }
   ],
   "source": [
    "m_filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "process_fire_data(m_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the file spot with distance 1000 km from the station\n",
    "distance = 1000 # km\n",
    "\n",
    "filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv'\n",
    "\n",
    "fire_all = pd.DataFrame()\n",
    "\n",
    "for file in v_files:\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round()\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round()\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "    \n",
    "    fire_all = pd.concat([fire_all,f],ignore_index=True)  \n",
    "     \n",
    "        \n",
    "fire_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (10,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'bright_ti4', 'scan', 'track', 'acq_date',\n",
       "       'acq_time', 'satellite', 'instrument', 'confidence', 'version',\n",
       "       'bright_ti5', 'frp', 'type', 'lat_km', 'long_km', 'daynight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop (9092222, 18)\n",
      "after drop (6925015, 18)\n"
     ]
    }
   ],
   "source": [
    "process_fire_data('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire For Chiang Mai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3779468, 10)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['year' 'season'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-be2f93342166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'power'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'track'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'frp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'longitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'brightness'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'season'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'acq_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'track'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'scan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'frp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mfire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m_proc.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3993\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3994\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3995\u001b[0m         )\n\u001b[0;32m   3996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3933\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3934\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3935\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3967\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3968\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3969\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3970\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benny\\pyenv\\geo\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['year' 'season'] not found in axis\""
     ]
    }
   ],
   "source": [
    "city_info = {'Country': 'Thailand',\n",
    " 'City': 'Chiang Mai',\n",
    " 'City (ASCII)': 'Chiang Mai',\n",
    " 'Region': 'Chiang Mai',\n",
    " 'Region (ASCII)': 'Chiang Mai',\n",
    " 'Population': '200952',\n",
    " 'Latitude': '18.7904',\n",
    " 'Longitude': '98.9847',\n",
    " 'Time Zone': 'Asia/Bangkok'}\n",
    "\n",
    "x = merc_x(city_info['Longitude'])\n",
    "y = merc_y(city_info['Latitude'])\n",
    "stepx = 800E3\n",
    "stepy = stepx\n",
    "\n",
    "#fire_v = pd.read_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_v.csv')\n",
    "m_filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m.csv'\n",
    "fire = pd.read_csv(m_filename, dtype={'version': str})\n",
    "columns_to_drop = ['acq_date','satellite','instrument','version','daynight','bright_t31','type']\n",
    "fire = fire.drop(columns_to_drop,axis=1)\n",
    "fire['datetime'] = pd.to_datetime(fire['datetime'])\n",
    "fire = fire.sort_values('datetime')\n",
    "fire = fire.set_index('datetime')\n",
    "# remove the data before '2002-07-04' because there is only one satellite\n",
    "fire = fire.loc['2002-07-04':]\n",
    "print(fire.shape)\n",
    "\n",
    "\n",
    "# add distance columns\n",
    "fire['distance'] = np.sqrt((fire['lat_km'] - y/1000) **2 + ((fire['long_km'] - x/1000)**2))\n",
    "\n",
    "# create power column and drop unncessary columns\n",
    "fire['power'] = fire['scan']*fire['track']*fire['frp']\n",
    "fire['count'] = 1\n",
    "fire = fire.drop(['latitude', 'longitude', 'brightness','year','season','acq_time','track','scan','frp'], axis=1)\n",
    "fire.to_csv('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/cm_proc/file_m_proc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impove Speed of Files reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_km = 2117.0 \n",
    "long_km = 11019.0\n",
    "m_files = glob('C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [16:11<00:00, 44.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# check the time without threading  \n",
    "file_all = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(m_files):\n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[f['lat_km'] <= (lat_km+1000)]\n",
    "    f = f[f['lat_km'] >= (lat_km-1000)]\n",
    "    # remove by long \n",
    "\n",
    "    f = f[f['long_km'] <= (long_km+1000)]\n",
    "    f = f[f['long_km'] >= (long_km-1000)]\n",
    "     \n",
    "    file_all = pd.concat([file_all,f],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_fire(file,lat_km, long_km):\n",
    "   \n",
    "    f = pd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "    # remove by long \n",
    "    f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "    return f\n",
    " \n",
    "\n",
    "def read_fire_dd(file,lat_km, long_km):\n",
    "   \n",
    "    f = dd.read_csv(file)\n",
    "     \n",
    "    # convert lat \n",
    "    f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "    f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "    # remove by lat \n",
    "    f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "    # remove by long \n",
    "    f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "    return f\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_fires(files,lat_km, long_km):\n",
    "    \n",
    "    all_fire = pd.DataFrame()\n",
    "    for file in files:\n",
    "        if file != None:\n",
    "            f = pd.read_csv(file)\n",
    "     \n",
    "            # convert lat \n",
    "            f['lat_km'] = (f['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "            f['long_km'] = (merc_x(f['longitude'])/1E3).round().astype(int)\n",
    "            # remove by lat \n",
    "            f = f[(f['lat_km'] <= (lat_km+1000)) & (f['lat_km'] >= (lat_km-1000))]\n",
    "            # remove by long \n",
    "            f = f[(f['long_km'] <= (long_km+1000)) & (f['long_km'] >= (long_km-1000))]\n",
    "            all_fire = pd.concat([all_fire, f], ignore_index=True)\n",
    "    return all_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229176, 17)\n",
      "(235249, 17)\n",
      "(214976, 17)\n",
      "(234913, 17)\n",
      "(165272, 17)\n",
      "(288160, 17)\n",
      "(230523, 17)\n",
      "(176189, 17)\n",
      "(276734, 17)\n",
      "(198856, 17)\n",
      "(225431, 17)\n",
      "(276406, 17)\n",
      "(7802, 17)\n",
      "(2898, 17)\n",
      "(195966, 17)\n",
      "(45055, 17)\n",
      "(210563, 17)\n",
      "(198697, 17)\n",
      "(142868, 17)\n",
      "(155097, 17)\n",
      "(49102, 16)\n",
      "(149221, 17)\n",
      "Wall time: 13min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try with threadpoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    future_list = [executor.submit(read_fire, file, lat_km, long_km) for file in m_files]\n",
    "    fire_all = pd.DataFrame()\n",
    "    for future in concurrent.futures.as_completed(future_list):\n",
    "        df = future.result()\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251721, 17)\n",
      "(860144, 17)\n",
      "(914314, 17)\n",
      "(204199, 17)\n",
      "(977427, 17)\n",
      "(701349, 17)\n",
      "Wall time: 17min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    future_list = [executor.submit(read_fires, group, lat_km, long_km) for group in grouper(m_files, 4)]\n",
    "    fire_all = pd.DataFrame()\n",
    "    for future in concurrent.futures.as_completed(future_list):\n",
    "        df = future.result()\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/fire_map/world_2000-2020/M6\\\\fire_archive_M6_100871.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(m_files[0])\n",
    "df['lat_km'] = (df['latitude'].apply(merc_y)/1E3).round().astype(int)\n",
    "df['long_km'] = (merc_x(df['longitude'])/1E3).round().astype(int)\n",
    "# remove by lat \n",
    "df = df[(df['lat_km'] <= (lat_km+1000)) & (df['lat_km'] >= (lat_km-1000))]\n",
    "# remove by long \n",
    "df = df[(df['long_km'] <= (long_km+1000)) & (df['long_km'] >= (long_km-1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>brightness</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_t31</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>type</th>\n",
       "      <th>lat_km</th>\n",
       "      <th>long_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>23.4521</td>\n",
       "      <td>107.8448</td>\n",
       "      <td>307.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>410</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>66</td>\n",
       "      <td>6.2</td>\n",
       "      <td>286.6</td>\n",
       "      <td>49.5</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>23.4631</td>\n",
       "      <td>107.8534</td>\n",
       "      <td>304.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>410</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>58</td>\n",
       "      <td>6.2</td>\n",
       "      <td>286.7</td>\n",
       "      <td>37.4</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2671</td>\n",
       "      <td>12006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>21.6968</td>\n",
       "      <td>103.0861</td>\n",
       "      <td>318.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>79</td>\n",
       "      <td>6.2</td>\n",
       "      <td>291.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2459</td>\n",
       "      <td>11475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>21.6998</td>\n",
       "      <td>103.0696</td>\n",
       "      <td>309.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>69</td>\n",
       "      <td>6.2</td>\n",
       "      <td>292.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2460</td>\n",
       "      <td>11474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>22.1135</td>\n",
       "      <td>101.1773</td>\n",
       "      <td>305.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>411</td>\n",
       "      <td>Terra</td>\n",
       "      <td>MODIS</td>\n",
       "      <td>61</td>\n",
       "      <td>6.2</td>\n",
       "      <td>289.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2509</td>\n",
       "      <td>11263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     latitude  longitude  brightness  scan  track    acq_date  acq_time  \\\n",
       "259   23.4521   107.8448       307.5   3.4    1.7  2015-01-01       410   \n",
       "260   23.4631   107.8534       304.2   3.4    1.7  2015-01-01       410   \n",
       "261   21.6968   103.0861       318.7   1.7    1.3  2015-01-01       411   \n",
       "262   21.6998   103.0696       309.5   1.7    1.3  2015-01-01       411   \n",
       "263   22.1135   101.1773       305.3   1.3    1.1  2015-01-01       411   \n",
       "\n",
       "    satellite instrument  confidence  version  bright_t31   frp daynight  \\\n",
       "259     Terra      MODIS          66      6.2       286.6  49.5        D   \n",
       "260     Terra      MODIS          58      6.2       286.7  37.4        D   \n",
       "261     Terra      MODIS          79      6.2       291.9  35.2        D   \n",
       "262     Terra      MODIS          69      6.2       292.6  19.3        D   \n",
       "263     Terra      MODIS          61      6.2       289.2   9.1        D   \n",
       "\n",
       "     type  lat_km  long_km  \n",
       "259     0    2670    12005  \n",
       "260     0    2671    12006  \n",
       "261     0    2459    11475  \n",
       "262     0    2460    11474  \n",
       "263     0    2509    11263  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# try with dask\n",
    "all_fire = [read_fire_dd(file,lat_km, long_km) for file in m_files]\n",
    "all_fire = dd.concat(all_fire)\n",
    "fire_df = all_fire.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))\n",
    "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_fire_list = Parallel(n_jobs=2)(delayed(read_fire)(file, lat_km, long_km) for file in m_files)\n",
    "fire_df = pd.concat(all_fire_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Weather Data from OpenWeatherMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data \n",
    "final_filename = 'C:/Users/Benny/Documents/Fern/aqi_thailand2/data/weather_cities/Soc_Son.csv'\n",
    "wea = pd.read_csv(filename)\n",
    "wea['datetime'] = pd.to_datetime(wea['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Users/Benny/Documents/Fern/BKK-AQI/data/weather_cities/Soc_Son/'\n",
    "files = glob(folder+'*.csv')\n",
    "# process data from OpenWeatherMap.org \n",
    "wea_df = pd.read_csv(files[0])\n",
    "wea_df = proc_open_weather(wea_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wea = pd.concat([wea_df,wea])\n",
    "new_wea = new_wea.sort_values(['datetime','Dew Point(C)'],ignore_index=True)\n",
    "new_wea = new_wea.drop_duplicates('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temperature(C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Wind Speed(kmph)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Precip.(in)</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Dew Point(C)</th>\n",
       "      <th>Wind Gust(kmph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172204</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>12:30 AM</td>\n",
       "      <td>12.22</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172205</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>12.22</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172207</th>\n",
       "      <td>2019-01-01 01:30:00</td>\n",
       "      <td>1:30 AM</td>\n",
       "      <td>12.22</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172208</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>2:00 AM</td>\n",
       "      <td>12.22</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172210</th>\n",
       "      <td>2019-01-01 02:30:00</td>\n",
       "      <td>2:30 AM</td>\n",
       "      <td>12.22</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172211</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>3:00 AM</td>\n",
       "      <td>11.11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172213</th>\n",
       "      <td>2019-01-01 03:30:00</td>\n",
       "      <td>3:30 AM</td>\n",
       "      <td>11.11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172214</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>4:00 AM</td>\n",
       "      <td>11.11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172216</th>\n",
       "      <td>2019-01-01 04:30:00</td>\n",
       "      <td>4:30 AM</td>\n",
       "      <td>11.11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172217</th>\n",
       "      <td>2019-01-01 05:00:00</td>\n",
       "      <td>5:00 AM</td>\n",
       "      <td>11.11</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime      Time  Temperature(C)  Humidity(%) Wind  \\\n",
       "172204 2019-01-01 00:30:00  12:30 AM           12.22         67.0   NE   \n",
       "172205 2019-01-01 01:00:00   1:00 AM           12.22         67.0   NE   \n",
       "172207 2019-01-01 01:30:00   1:30 AM           12.22         67.0   NE   \n",
       "172208 2019-01-01 02:00:00   2:00 AM           12.22         62.0   NE   \n",
       "172210 2019-01-01 02:30:00   2:30 AM           12.22         62.0  NNE   \n",
       "172211 2019-01-01 03:00:00   3:00 AM           11.11         67.0  NNE   \n",
       "172213 2019-01-01 03:30:00   3:30 AM           11.11         67.0  NNE   \n",
       "172214 2019-01-01 04:00:00   4:00 AM           11.11         67.0  NNE   \n",
       "172216 2019-01-01 04:30:00   4:30 AM           11.11         67.0  NNE   \n",
       "172217 2019-01-01 05:00:00   5:00 AM           11.11         62.0  NNE   \n",
       "\n",
       "        Wind Speed(kmph)  Pressure(in)  Precip.(in)      Condition  \\\n",
       "172204               8.0         30.36          0.0  Mostly Cloudy   \n",
       "172205              11.0         30.36          0.0  Mostly Cloudy   \n",
       "172207              10.0         30.36          0.0  Mostly Cloudy   \n",
       "172208              14.0         30.34          0.0  Mostly Cloudy   \n",
       "172210              13.0         30.34          0.0  Mostly Cloudy   \n",
       "172211              13.0         30.34          0.0  Mostly Cloudy   \n",
       "172213              10.0         30.34          0.0  Mostly Cloudy   \n",
       "172214              14.0         30.34          0.0  Mostly Cloudy   \n",
       "172216              11.0         30.34          0.0  Mostly Cloudy   \n",
       "172217              13.0         30.34          0.0  Mostly Cloudy   \n",
       "\n",
       "        Dew Point(C)  Wind Gust(kmph)  \n",
       "172204          6.11              0.0  \n",
       "172205          6.11              0.0  \n",
       "172207          6.11              0.0  \n",
       "172208          5.00              0.0  \n",
       "172210          5.00              0.0  \n",
       "172211          5.00              0.0  \n",
       "172213          5.00              0.0  \n",
       "172214          5.00              0.0  \n",
       "172216          5.00              0.0  \n",
       "172217          3.89              0.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wea[new_wea['datetime'] > '2019-01-01'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wea.to_csv(final_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data From Hanoi US Embassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 389775 / 389775"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/us_emb/Hanoi_PM2.5_2020_YTD (1).csv'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('http://dosairnowdata.org/dos/historical/Hanoi/2020/Hanoi_PM2.5_2020_YTD.csv','../data/us_emb/Hanoi_PM2.5_2020_YTD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
